<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <script type="text/javascript">/*<![CDATA[*/
  /*
  March 19, 2004 MathHTML (c) Peter Jipsen http://www.chapman.edu/~jipsen
  Released under the GNU General Public License version 2 or later.
  See the GNU General Public License (at http://www.gnu.org/copyleft/gpl.html)
  for more details.
  */
  
  function convertMath(node) {// for Gecko
    if (node.nodeType==1) {
      var newnode =
        document.createElementNS("http://www.w3.org/1998/Math/MathML",
          node.nodeName.toLowerCase());
      for(var i=0; i < node.attributes.length; i++)
        newnode.setAttribute(node.attributes[i].nodeName,
          node.attributes[i].value);
      for (var i=0; i<node.childNodes.length; i++) {
        var st = node.childNodes[i].nodeValue;
        if (st==null || st.slice(0,1)!=" " && st.slice(0,1)!="\n")
          newnode.appendChild(convertMath(node.childNodes[i]));
      }
      return newnode;
    }
    else return node;
  }
  
  function convert() {
    var mmlnode = document.getElementsByTagName("math");
    var st,str,node,newnode;
    for (var i=0; i<mmlnode.length; i++)
      if (document.createElementNS!=null)
        mmlnode[i].parentNode.replaceChild(convertMath(mmlnode[i]),mmlnode[i]);
      else { // convert for IE
        str = "";
        node = mmlnode[i];
        while (node.nodeName!="/MATH") {
          st = node.nodeName.toLowerCase();
          if (st=="#text") str += node.nodeValue;
          else {
            str += (st.slice(0,1)=="/" ? "</m:"+st.slice(1) : "<m:"+st);
            if (st.slice(0,1)!="/")
               for(var j=0; j < node.attributes.length; j++)
                 if (node.attributes[j].value!="italic" &&
                   node.attributes[j].value!="" &&
                   node.attributes[j].value!="inherit" &&
                   node.attributes[j].value!=undefined)
                   str += " "+node.attributes[j].nodeName+"="+
                       "\""+node.attributes[j].value+"\"";
            str += ">";
          }
          node = node.nextSibling;
          node.parentNode.removeChild(node.previousSibling);
        }
        str += "</m:math>";
        newnode = document.createElement("span");
        node.parentNode.replaceChild(newnode,node);
        newnode.innerHTML = str;
      }
  }
  
  if (document.createElementNS==null) {
    document.write("<object id=\"mathplayer\"\
    classid=\"clsid:32F66A20-7614-11D4-BD11-00104BD3F987\"></object>");
    document.write("<?import namespace=\"m\" implementation=\"#mathplayer\"?>");
  }
  if(typeof window.addEventListener != 'undefined'){
    window.addEventListener('load', convert, false);
  }
  if(typeof window.attachEvent != 'undefined') {
    window.attachEvent('onload', convert);
  }
  /*]]>*/
  </script>
</head>
<body>
<div id="TOC">
<ul>
<li><a href="#определения">Определения</a></li>
<li><a href="#математическая-постановка-задачи.">Математическая постановка задачи.</a></li>
<li><a href="#функциональные-модели">Функциональные модели</a></li>
<li><a href="#идентифицируемость-непрерывных-моделей-с-аддитивным-шумом">Идентифицируемость непрерывных моделей с аддитивным шумом</a></li>
<li><a href="#тестирование-на-модельных-данных">Тестирование на модельных данных</a></li>
</ul>
</div>
<p><a href="https://arxiv.org/abs/1309.6779">Исходная статья: Causal Discovery with Continuous Additive Noise Models</a> - <em>Отличается от первоначально выбранной!</em></p>
<p>Популярным средством измерения силы причинно-следственной связи процессов, протекающих в природе или обществе, является корреляция. Однако существует принцип, который формулируется довольно просто: “correlation does not mean causation”. Пренебрежение им может порождать так называемые «ложные корреляции»: например, количество гнёзд аистов влияет на рождаемость в европейских странах или количество фильмов, в которых снялся Николас Кейдж, может быть каким-то образом связано с гибелью людей в бассейнах. <img src="http://i.imgur.com/sKwYC0Y.png" alt="Storks" /> <img src="http://i.imgur.com/DvqDAbM.png" alt="Nicolas Cage" /></p>
<p>Возникает естественный вопрос: в каких случаях “correlation DOES mean causation”? На этот вопрос пытается ответить <a href="https://ei.is.tuebingen.mpg.de/research_groups/causal-inference-group">группа исследователей из Института интеллектуальных система Макса Планка.</a> Оказывается, при выполнении некоторых условий, можно восстановить причинно-следственную связь из результатов наблюдений.</p>
<p>Для исследования причинно-следственных связей между процессами <a href="https://ru.wikipedia.org/wiki/%D0%9F%D0%B5%D1%80%D0%BB,_%D0%94%D0%B6%D1%83%D0%B4%D0%B0">Джуда Пёрл</a> предложил использовать фунцкиональные причинные модели (functional causal models). По уравнениям, описывающим причинную модель, можно построить граф, который отображает зависимости между случайными величинами, но не описывает характера таких зависимостей. Таким образом, граф содержит меньше информации о модели, однако позволяет ввести в терминах теории графов некоторые критерии, упрощающие определение условной независимости между переменными. Эти понятия неразрывно связаны с понятием байесовских сетей.</p>
<h3 id="определения">Определения</h3>
<p>[more definitions come here…]</p>
<p>Ориентированный ациклический граф (DAG, directed acyclic graph) — это ориентированный граф, в котором отсутствуют направленные циклы, то есть пути, начинающиеся и закончивающиеся в одной и той же вершине.</p>
<p>Пусть $ (X_i)_{i V} $ — семейство случайных величин, $ G = (V, E) $ — DAG с вершинами $ E V^2 $. Как правило, в литературе используют обозначения $ X_i $ и $ i $ для соответствующих вершин графа.</p>
<p>$ X_i $ называется вершиной-родителем вершины $ X_j $, если $ (i, j) E $, и вершиной-ребёнком, если $ (j, i) E $. Множество вершин-родителей вершины $ X_j $ обозначатся $ pa_j $, множество вершин-детей — $ ch_j $.</p>
<p>Направленным путём в графе $ G $ называется последовательность различных вершин $ X_{i_1}, …, X_{i_n} $, для которых $ (i_k, i_{k+1}) E $ или $ (i_{k+1}, i_k) E $ для $ k = 1, …, n - 1 $. Если между вершинами $ X_{i_1} $ и $ X_{i_n} $ есть направленный путь, вершина $ X_{i_n} $ называется потомком вершины $ X_{i_1} $.</p>
<p>Множество всех потомков вершины $ X_i $ обозначается $ de_i $, множество вершин не-потомков — $ nd_i $.</p>
<p>Путь между $ X_{i_1} $ и $ X_{i_n} $ называется заблокированным множеством $ S $ (не включая ни $ X_{i_1} $, ни $ X_{i_n} $), если существует такая вершина $ X_{i_k} $, что выполняется одно из условий: 1. $ X_{i_k} S $ и - $ X_{i_{k-1}} X_{i_k} X_{i_{k+1}} $ или - $ X_{i_{k-1}} X_{i_k} X_{i_{k+1}} $ или - $ X_{i_{k-1}} X_{i_k} X_{i_{k+1}} $ 2. $ X_{i_{k-1}} X_{i_k} X_{i_{k+1}} $ и ни $ X_{i_k} $, ни её потомки не принадлежат $ S $.</p>
<p>Говорят, что два непересекающихся множества вершин $ A $ и $ B $ d-разделены (непересекающимся с ними множеством $ S $), если каждый путь между вершинами $ A $ и $ B $ заблокирован множеством $ S $.</p>
<p>Совместное распределение $ ^{(X_i)_{i V}} $ называется марковым относительно DAG $ G $, если $ A $ и $ B $ d-разделены $ C $ $ A ⫫ B C $ для всех непересекающихся множеств $ A, B, C $.</p>
<p>Два графа называются марковски эквивалентными, если в них выполняются одинаковые наборы d-разделимости, т. е. имеют одинаковые наборы условных независимостей совместного распределения.</p>
<p>Лемма. Два DAG являются марковски эквивалентными тогда и только тогда, когда они имеют одинаковые остовы и одинаковые v-структуры.</p>
<p>Понятие причинной минимальности может быть сформулировано следующим способом.</p>
<p>Предложение. Пусть заданы случайный вектор $ X = (X_1, , X_p) $ и совместное распределение на нём $  $ — марково относительно $  $. Тогда $  $ отвечает причинной минимальности относительно $  $ тогда и только тогда, когда $ X_j Y PA_{j}^{} выполняется $ X_j !!!!Y | PA_{j}^{}  {Y} $.</p>
<p>Для всех рассматриваемых графов предполагается ацикличность (отсутствие циклов в причинно-следственных связях) и достаточность (в рассмотрение принимаются все переменные, являющиеся общей причиной двух и более других переменных).</p>
<p>Для строгого определения истинного причинного графа пользуются так называемой do-нотацией, предложенной Джудой Пёрлом.</p>
<p>Определение. Пусть $ X = (X_1, , X_p) $ — семейство случайных величин с совместным распределением $  $, абсолютно непрерывным относительно меры Лебега. Для направленного ациклического графа $  $, заданного над $ X $, будем называть интервенционным распределением (interventional distribution) $ do(X_j = (x_j)) $ величин $ X_1, , X_p $ <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>x</mi><mi>p</mi></msub><mo stretchy="false" form="prefix">|</mo><mi>d</mi><mi>o</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>X</mi><mi>j</mi></msub><mo>=</mo><mover><mi>p</mi><mo accent="true">̃</mo></mover><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="postfix">)</mo><mo stretchy="false" form="postfix">)</mo><mo>=</mo><munderover><mo>∏</mo><mrow><mi>i</mi><mo>≠</mo><mi>j</mi></mrow><mi>p</mi></munderover><mi>p</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>x</mi><mrow><mi>P</mi><msub><mi>A</mi><mi>i</mi></msub></mrow></msub><mo stretchy="false" form="postfix">)</mo><mo>⋅</mo><mover><mi>p</mi><mo accent="true">̃</mo></mover><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>,</mo></mrow><annotation encoding="application/x-tex"> p(x_1, \dots, x_p | do(X_j = \tilde{p}(x_j))) = \prod_{i \ne j}^p p(x_i | x_{PA_i} ) \cdot \tilde{p}(x_j), </annotation></semantics></math> если $ p(x_1, , x_p) &gt; 0 $, и 0 в другом случае.</p>
<p>Иначе говоря, запись $ do(X_j = (x_j )) $ означает назначение значения переменной $ X_j $ случайным образом из распределения $ (x_j) $ независимо от значения её родителей.</p>
<p>Под $ x_{PA_i} $ понимается набор всех $ X_j $, которые являются непосредственными родителями $ X_i $ в графе $  $.</p>
<p>Выражение $ p(x_1, , x_p | do(X_j = _j, j J)) $ задаёт распределение над $ X_1, , X_p $.</p>
<p>Определение. Пусть даны $ (X) $ — распределение над $ X_1, , X_p $ — и распределения $ _{do(X_j = (x_j), j J)}(X) $ для всех $ J V = {1, , p} $. Будем называеть граф $ _c $ истинным причинным графом, если: - $ _c $ — это направленный ациклический граф, - распределение $ (X) $ марково относительно $ <em>c $; - для всех $ J V $ и $ (x_j), j J $ распределение $ </em>{do(X_j = (x_j), j J)}(X) $ совпадает с $ p(x_1, , x_p | do(X_j = (x_j)), j J), вычисленным для $ _c $ в предыдущем определении.</p>
<p>Вообще говоря, может существовать несколько истинных причинных графов.</p>
<h3 id="математическая-постановка-задачи.">Математическая постановка задачи.</h3>
<h3 id="функциональные-модели">Функциональные модели</h3>
<p>Structural equation model (SEM) или иначе функциональная модель задаётся как пара $ (, (N)) $, где $  = (S_1, , S_p) $ — набор $ p $ уравнений</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>j</mi></msub><mo>:</mo><mspace width="1.0em"></mspace><msub><mi>X</mi><mi>j</mi></msub><mo>=</mo><msub><mi>f</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">(</mo><mi>P</mi><msub><mi>A</mi><mi>j</mi></msub><mo>,</mo><msub><mi>N</mi><mi>j</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>,</mo><mspace width="1.0em"></mspace><mi>j</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>p</mi></mrow><annotation encoding="application/x-tex"> S_j: \quad X_j = f_i(PA_j, N_j), \quad j = 1, \dots, p </annotation></semantics></math></p>
<p>и $ (N) = (N_1, , N_p) $ — совместное распределение шумовых переменных, от которых требуется независимость в совокупности.</p>
<p>Функциональная модель задаёт, как образом $ PA_j $ оказывают влияние на $ X_j $.</p>
<p>Граф, полученный из функциональной модели, позволяет факторизовать совместную плотность распределения по следующей формуле:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathvariant="script"><mi>ℒ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><mi>X</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mstyle mathvariant="script"><mi>ℒ</mi></mstyle><mo stretchy="false" form="prefix">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>X</mi><mi>p</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>=</mo><munder><mo>∏</mo><mi>j</mi></munder><mi>p</mi><mo stretchy="false" form="prefix">(</mo><msub><mi>X</mi><mi>j</mi></msub><mo>∣</mo><mi>p</mi><msub><mi>a</mi><mi>j</mi></msub><mo stretchy="false" form="postfix">)</mo><mi>.</mi></mrow><annotation encoding="application/x-tex"> \mathcal{L}(X) = \mathcal{L}(X_1, \dots, X_p) = \prod_j p(X_j \mid pa_j). </annotation></semantics></math></p>
<p>Т.,е., достаточно рассматривать непосредственных родителей каждой из вершин.</p>
<p>Предложение. Пусть $ X_1, , X_p $ — случайные величины, $ (X) $ — их совместное распределение относительно $  $. Тогда существуют SEM $ (, (N)) $ и граф $  $, порождающие распределение $ (X) $.</p>
<p>Дополнительно вводится определение идентифицируемости.</p>
<p>Определение. Пусть распределение $ (X) = (X_1, , X_p) $ получено по (неизвестной) функциональной модели с графом $ _0 $, в частности, $ (X) $ марково относительно $ _0 $. Будем называеть $ _0 $ идентифицируемым по $ (X) $, если распределение $ (X) $ не могло быть получено по той же функциональной модели с графом $  _0 $.</p>
<p>Как правило, $ _0 $ не идентифицируем по $ (X) $, поскольку совместное распределение $ (X) $ обычно является марковым относительно большого количества различных графов. Однако наложение некоторых дополнительных требований позволяет добиться идентифицируемости ограниченных моделей.</p>
<h3 id="идентифицируемость-непрерывных-моделей-с-аддитивным-шумом">Идентифицируемость непрерывных моделей с аддитивным шумом</h3>
<p>Рассмотрим функциональные модели следующего вида: $ X_j = f_j(PA_j) + N_j, j = 1, , p $, где $ N_j $ имеют строго положительные распределения.</p>
<p>Для таких моделей требование причинной минимальности упрощается.</p>
<p>Предложение. Пусть в описанной модели функции $ f_i $ не являются постоянными ни по одному из их аргументов, т.,е. для всех $ i PA_j $ существуют некоторые $ x_{PA_j  {i} $ и $ x_i x_i’ $ такие, что <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>j</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>P</mi><msub><mi>A</mi><mi>j</mi></msub><mspace width="0.222em"></mspace><mi>i</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false" form="postfix">)</mo><mo>≠</mo><msub><mi>f</mi><mi>j</mi></msub><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mrow><mi>P</mi><msub><mi>A</mi><mi>j</mi></msub><mspace width="0.222em"></mspace><mi>i</mi></mrow></msub><mo>,</mo><msub><mi>x</mi><mi>i</mi></msub><mi>′</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex"> f_j(x_{PA_j \ {i}}, x_i) \ne f_j(x_{PA_j \ {i}}, x_i&#39;) </annotation></semantics></math>. Тогда совместное распределение, полученное по этой модели, отвечает требованию причинной минимальности относительно соответствующего графа.</p>
<h4 id="модели-с-аддитивным-шумом-двух-переменных">Модели с аддитивным шумом двух переменных</h4>
<p>Идентифицируемость моделей с аддитивным шумом двух переменных возможна при выполнении любопытного условия.</p>
<p>Условие 1. Модель двух переменных с аддитивным шумом $ X_1 = N_1 $ и $ X_2 = f_2(X_1) + N_2 $ является идентифицируемой, если тройка $ (f_2, (X_1), (N_2)) $ не является решением дифференциального уравнения <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ξ</mi><mi>‴</mi><mo>=</mo><mi>ξ</mi><mi>″</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>−</mo><mfrac><mrow><mi>ν</mi><mi>‴</mi><mi>f</mi><mi>′</mi></mrow><mrow><mi>ν</mi><mi>″</mi></mrow></mfrac><mo>+</mo><mfrac><mrow><mi>f</mi><mi>″</mi></mrow><mrow><mi>f</mi><mi>′</mi></mrow></mfrac><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mn>2</mn><mi>ν</mi><mi>″</mi><mi>f</mi><mi>″</mi><mi>f</mi><mi>′</mi><mo>+</mo><mi>ν</mi><mi>′</mi><mi>f</mi><mi>‴</mi><mo>+</mo><mfrac><mrow><mi>ν</mi><mi>′</mi><mi>ν</mi><mi>‴</mi><mi>f</mi><mi>″</mi><mi>f</mi><mi>′</mi></mrow><mrow><mi>n</mi><mi>u</mi><mi>″</mi></mrow></mfrac><mo>−</mo><mfrac><mrow><mi>n</mi><mi>u</mi><mi>′</mi><mo stretchy="false" form="prefix">(</mo><mi>f</mi><mi>″</mi><msup><mo stretchy="false" form="postfix">)</mo><mn>2</mn></msup></mrow><mrow><mi>f</mi><mi>′</mi></mrow></mfrac><mo>,</mo></mrow><annotation encoding="application/x-tex"> \xi&#39;&#39;&#39; = \xi&#39;&#39; \left( -\frac{\nu&#39;&#39;&#39; f&#39;}{\nu&#39;&#39;} + \frac{f&#39;&#39;}{f&#39;} \right) - 2 \nu&#39;&#39; f&#39;&#39; f&#39; + \nu&#39; f&#39;&#39;&#39; + \frac{\nu&#39; \nu&#39;&#39;&#39; f&#39;&#39; f&#39;}{nu&#39;&#39;} - \frac{nu&#39; (f&#39;&#39;)^2}{f&#39;}, </annotation></semantics></math> где $ f = f_2, =  + N_j, j = 1, , p, $$ где все $ N_j $ независимы в совокупности и распределены не нормально, и для $ j { 1, , p } <em>{jk} 0 $ для всех $ k PA</em>{j}^{_0} $. Тогда граф $ _0 $ идентифицируем по совместному распределению.</p>
<h3 id="тестирование-на-модельных-данных">Тестирование на модельных данных</h3>
<p>Авторы проверяют точность работы алгоритма на тестовых наборах данных, сгенерированных для линейных и нелинейных $ f_i $ в SEM. Эксперименты показывают, что RESIT оказывается лучше метода PC, а в случае $ p = 15 $ переменных справляется с определением структуры графа для нелинейных SEM.</p>
<p>Упрощённая версию алгоритма была протестирована на <a href="webdav.tuebingen.mpg.de/cause-effect/">коллекции пар «причина—следствие»</a>, полученных из различных предметных областей. Для каждой пары требовалось указать, какая переменная является непосредственной причиной другой. (Похожим образом была поставлена задача в одном из соревнований Kaggle: https://www.kaggle.com/c/cause-effect-pairs/.) Предложенный алгоритм показал точность около 80% на наборе из 86 пар.</p>
</body>
</html>
