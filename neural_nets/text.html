<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="russian" xml:lang="russian">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Анастасия Миллер" />
  <title>Нейронные сети: принципы, проблемы, что работает, что нет и почему.</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<div id="header">
<h1 class="title"><p>Нейронные сети: принципы, проблемы, что работает, что нет и почему.</p></h1>
<h2 class="author">Анастасия Миллер</h2>
</div>
<div id="TOC">
<ul>
<li><a href="#про-мозг-передача-информации-путём-активации-нейронов.">Про мозг: передача информации путём активации нейронов.</a></li>
<li><a href="#перцептрон">Перцептрон</a></li>
<li><a href="#архитектура-полносвязной-сети-и-передача-информации-в-ней.">Архитектура полносвязной сети и передача информации в ней.</a><ul>
<li><a href="#нейронная-сеть-универсальный-аппроксиматор">Нейронная сеть – универсальный аппроксиматор</a></li>
</ul></li>
<li><a href="#задача-обучения-сети">Задача обучения сети</a><ul>
<li><a href="#метод-градиентного-спуска">Метод градиентного спуска</a></li>
<li><a href="#алгоритм-обратного-распространения-ошибки">Алгоритм обратного распространения ошибки</a></li>
</ul></li>
<li><a href="#примеры-неглубоких-сетей">Примеры неглубоких сетей</a><ul>
<li><a href="#autoencoder">Autoencoder</a></li>
<li><a href="#word2vec">Word2Vec</a></li>
</ul></li>
<li><a href="#проблемы">Проблемы</a></li>
<li><a href="#решения">Решения</a><ul>
<li><a href="#convolutional-neural-networks">Convolutional neural networks</a></li>
<li><a href="#local-vs.global-optimization">Local vs. global optimization</a></li>
<li><a href="#optional-recurrent-neural-networks">[optional] Recurrent neural networks</a></li>
</ul></li>
</ul>
</div>
<h2 id="про-мозг-передача-информации-путём-активации-нейронов.">Про мозг: передача информации путём активации нейронов.</h2>
<p>Идея, стоящая за созданием нейронных сетей, заключается в том, чтобы промоделировать работу человеческого мозга. Очень общее и условное представление об устройстве и работе клетки человеческого мозга и легло в основу математической модели “нейронная сеть”. Естественный нейрон в коре головного мозга, согласно этому представлению, выглядит следующим образом:</p>
<p>Клетка имеет множество разветвлённых отростков — дендритов, и одно длинное тонкое волокно — аксон, на конце которого находятся синапсы, примыкающие к дендритам других нервных клеток. Каждая нервная клетка может находиться в двух состояниях: обычном и возбуждённном. В возбуждённом состоянии клетка генерирует электрический импульс, который проходит по аксону до синапсов. Синапс при приходе импульса выделяет вещество, способствующее проникновению положительных зарядов внутрь соседней клетки. Синапсы имеют разную способность концентрировать это вещество, некоторые даже препятствуют его выделению — они называются тормозящими. Если суммарный заряд, попавший в клетку, превосходит некоторый порог, клетка возбуждается и генерирует импульс, который распространяется по аксону и доходит до синапсов, что способствует возбуждению следующих клеток. После возбуждения клетки наступает период релаксации — некоторое время она не способна генерировать новые импульсы. Благодаря этому клетки работают по тактам, наподобие дискретных автоматов, а сеть в целом передаёт направленную волну импульсов. <span class="citation">(Воронцов 2007)</span></p>
<h2 id="перцептрон">Перцептрон</h2>
<p>Естественной формализацией этого описания является следующая модель:</p>
<p>Пусть <span class="math">\(\mathcal X\)</span> — пространство объектов; <span class="math">\(\mathcal Y\)</span> — множество допустимых ответов; <span class="math">\(y^*: \mathcal X \to \mathcal Y\)</span> — целевая зависимость, известная только на объектах обучающей выборки <span class="math">\(X = \left\{ \left(x^{(i)}, y_i\right) \right\}_{i = 1}^\ell, \forall i \in 1\mathbin{:}\ell \:y_i = y^*(x^{(i)})\)</span>. Требуется построить алгоритм <span class="math">\(a: X \to Y\)</span>, аппроксимирующий целевую зависимость <span class="math">\(y^*\)</span> на всём множестве <span class="math">\(\mathcal X\)</span>.</p>
<p>Будем предполагать, что объекты описываются <span class="math">\(n\)</span> числовыми признаками <span class="math">\(\left(x^{(i)}_1, \ldots, x^{(i)}_n\right)\)</span> (такой вектор называется <em>признаковым описанием</em> объекта <span class="math">\(x^{(i)}\)</span>).</p>
<p>Значения этих признаков будем трактовать как величины импульсов, поступающих на вход нейрона через <span class="math">\(n\)</span> входных синапсов. Поступающие в нейрон импульсы складываются с весами <span class="math">\(w_1, \ldots, w_n\)</span>. Если вес положительный, то соответствующий синапс возбуждающий, если отрицательный, то тормозящий. Если суммарный импульс превышает заданный порог активации <span class="math">\(w_0\)</span>, то нейрон возбуждается и выдаёт на выходе 1, иначе выдаётся 0. То есть нейрон вычисляет следующую функцию:</p>
<p><span class="math">\[a(x) = \varphi\left(\sum_{j=1}^n w_j x_j\right), \text{ где } \varphi(z) = \begin{cases}1, z &gt; 0, \\ 0, z \leq 0\end{cases}.\]</span></p>
<p>В теории нейронных сетей функцию <span class="math">\(\varphi\)</span> принято называть <em>активационной функцией</em> нейрона.</p>
<p>Эта модель естественным образом расширяется: <span class="math">\(\varphi\)</span> может быть не ступенчатой функцией, а, например, сигмоидальной (<span class="math">\(\sigma(z) = 1 / \left(1 + e^{-z}\right)\)</span>), просто линейной (<span class="math">\(\mathrm{id}(z) = z\)</span>) или обрезанной линейной (<span class="math">\(\mathrm{ReLU}(z) = \max\left\{0, z\right\}\)</span>). В общем случае эта модель называется (однослойным) перцептроном.</p>
<p>Согласно той же биологический мотивации способность синапсов пропускать заряд (обозначенная в модели весами) изменяется в зависимости от того, какую задачу решает данный нейрон. Например, нейрон, сравнивающий два своих входа <span class="math">\(x_1\)</span> и <span class="math">\(x_2\)</span> и выдающий 1, если <span class="math">\(x_1 &gt; x_2\)</span>, 0 в обратном случае, будет иметь вектор весов <span class="math">\(\left(0, 1, -1\right)\)</span> (или любой другой пропорциональный): см. рис . А линейный классификатор вида <span class="math">\(a(x_1, x_2) = \begin{cases} 1, \text{если} 2 x_1 + 3 x_2 &gt; 5, \\ 0\:\text{иначе}\end{cases}\)</span> представим в виде нейрона с весами (-5, 2, 3): см. рис. .</p>
<p><img src="perceptron_scheme_1.png" alt="Перцептрон, реализующий функцию \max" /> <img src="perceptron_sample_1.png" alt="Перцептрон, реализующий функцию \max" /></p>
<p><img src="perceptron_scheme_2.png" alt="Перцептрон, реализующий a(x_1, x_2) = 1, \text{ если } 2 x_1 + 3 x_2 &gt; 5, 0 \text{ иначе }" /> <img src="perceptron_sample_2.png" alt="Перцептрон, реализующий a(x_1, x_2) = 1, \text{ если } 2 x_1 + 3 x_2 &gt; 5, 0 \text{ иначе }" /></p>
<h2 id="архитектура-полносвязной-сети-и-передача-информации-в-ней.">Архитектура полносвязной сети и передача информации в ней.</h2>
<p>Следующая идея состоит в том, что нейроны можно комбинировать. Ведь правда же, ничто не мешает нам результат вычисления одного нейрона рассматривать как входное значение для другого нейрона (как оно и происходит в мозгу)<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>.</p>
<p>На рис.  показана вычислительная схема двуслойной полносвязной нейронной сети. В ней можно выделить несколько похожих конструкций:</p>
<ul>
<li>узлы <span class="math">\(a^1_1\)</span>, <span class="math">\(a^1_2\)</span> и <span class="math">\(a^1_3\)</span> являются входами, а узел <span class="math">\(a^2_1\)</span> — выходом перцептрона с весами <span class="math">\(w^2_{11}, w^2_{12}, w^2_{13}\)</span> и суммирующей функцией <span class="math">\(z^2_1\)</span>;</li>
<li>узлы <span class="math">\(a^1_1\)</span>, <span class="math">\(a^1_2\)</span> и <span class="math">\(a^1_3\)</span> являются входами, а узел <span class="math">\(a^2_2\)</span> — выходом перцептрона с весами <span class="math">\(w^2_{21}, w^2_{22}, w^2_{23}\)</span> и суммирующей функцией <span class="math">\(z^2_2\)</span>;</li>
<li>узлы <span class="math">\(a^2_1\)</span> и <span class="math">\(a^2_1\)</span> являются входами, а узел <span class="math">\(a^3_1\)</span> — выходом перцептрона с весами <span class="math">\(w^3_{11}, w^3_{12}\)</span> и суммирующей функцией <span class="math">\(z^3_1\)</span>.</li>
</ul>
<p><img src="abstract_net_example.png" alt="изображение абстрактной нейронной сети" />{ width=70% }</p>
<p>В этих обозначениях есть некоторая двойственность. В зависимости от контекста и наличия/отсутствия круглых скобок <span class="math">\(z^i_j\)</span> и <span class="math">\(a^i_j\)</span> могут означать как сумматорную или активационную функцию, так и её значение на конкретных входных данных.</p>
<p>Таким образом, полносвязная нейронная сеть вычисляет следующую рекуррентную функцию:</p>
<p><span class="math">\[a^1_ i = \mathtt{input[}i\mathtt{]}\]</span> <span class="math">\[a^l_ i = a^l_ i(z^l_ i) = a^l_ i(\sum_ j w^l_ {ij} a^{l-1}_ j)\]</span></p>
<p>(здесь я уже подставила в качестве <span class="math">\(z^l_i\)</span> обычную суммирующую функцию). Активационная функция может быть какой угодно, обычно выбирается в зависимости от требований к области значений ответов: на внутренних слоях сигмоида, на наружных — сигмоида, арктангенс или ReLU. Почему такие — сейчас скажем.</p>
<p>Обобщая эту конструкцию, получаем систему, которую мы видели на первой картинке: <span class="math">\[a^l_ i = a^l_ i \left(\sum_j w^l_ {ij} a^{l-1}_j\right)\]</span></p>
<h3 id="нейронная-сеть-универсальный-аппроксиматор">Нейронная сеть – универсальный аппроксиматор</h3>
<p>Давайте теперь детально поговорим о том, какие именно функции нейросеть теоретически может вычислить. <span class="citation">(Воронцов 2011)</span></p>
<p>Опр.: Набор функций <span class="math">\(F \subset C(X)\)</span> называется замкнутым относительно функции <span class="math">\(\phi : \mathbb{R} \to \mathbb{R}\)</span>, если для любого <span class="math">\(f \in F\)</span> выполнено <span class="math">\(\phi(f) \in F\)</span>.</p>
<p>Т. <span class="citation">(Горбань et al. 1998)</span>: Пусть <span class="math">\(X\)</span> — компактное пространство, <span class="math">\(C(X)\)</span> — алгебра непрерывных на <span class="math">\(X\)</span> вещественных функций, <span class="math">\(F\)</span> — линейное подпространство в <span class="math">\(C(X)\)</span>, замкнутое относительно нелинейной непрерывной функции <span class="math">\(\phi\)</span>, содержащее константу (<span class="math">\(1 \in F\)</span>) и разделяющее точки множества <span class="math">\(X\)</span>. Тогда <span class="math">\(F\)</span> плотно в <span class="math">\(C(X)\)</span>.</p>
<p>То есть для любой функции <span class="math">\(g \in C(X)\)</span> можно взять одну нелинейную <span class="math">\(\phi\)</span> и суперпозицией её линейных комбинаций (которой и является нейросеть, если у всех нейронов активационные функции одинаковы) приблизить <span class="math">\(g\)</span> с любой заданной точностью. Проблема только в том, что теорема не говорит, как именно это сделать</p>
<h2 id="задача-обучения-сети">Задача обучения сети</h2>
<p>У нас есть некоторая непрерывная функция <span class="math">\(f: \mathbb{R}^N \to \mathbb{R}^k\)</span>, вида которой мы не знаем, а знаем только её значение на конечном наборе точек. Мы хотим построить её равномерное приближение.</p>
<p>NB: вообще-то задача классификации (когда у <span class="math">\(f\)</span> конечное множество значений) решается сетями едва ли не чаще, чем задача регрессии, но с теоретическими обоснованиями здесь хуже.</p>
<p>Теорема Вейерштрасса: <span class="math">\(\forall f: \mathbb{R}^n \to Q\)</span>, где <span class="math">\(Q\)</span> – замкнутое ограниченное множество, <span class="math">\(\forall \varepsilon &gt; 0\)</span> существует такой многочлен <span class="math">\(P(x_1, \ldots, x_n):\)</span> <span class="math">\[\mathrm{sup}_Q\left\Vert f(x_1, \ldots, x_n) - P(x_1, \ldots, x_n) \right\Vert &lt; \varepsilon\]</span></p>
<p>Проблемы:</p>
<ul>
<li>признаковое пространство <span class="math">\(\mathbb{R}^n\)</span> может быть очень большой размерности</li>
<li>а степень многочлена с повышением точности растёт</li>
<li>проклятие размерности не оставляет нас</li>
</ul>
<p>Будем строить приближение нейронной сетью с фиксированной архитектурой (тут важно заметить, что вообще-то от архитектуры сети зависит то, насколько хорошо мы сможем приблизить функцию, но перебор ещё и по архитектуре мы пока строить не будем). Функция, вычисляемая сетью при зафиксированной архитектуре сети, зависит только от множества её весов. То есть в общем случае мы приходим к задаче настройки весов сети, которая заключается в том, чтобы найти набор весов <span class="math">\[\{w_{ij}^l\} = \mathrm{arg\,min}_{\{w_{ij}^l\}} J\left(f, a\left(\left\{w_{ij}^l\right\}\right)\right),\]</span> где <span class="math">\(J\)</span> – функция, измеряющая расстояние между <span class="math">\(f\)</span> и <span class="math">\(a\left(\left\{w_{ij}^l\right\}\right)\)</span>.</p>
<p>Самый простой вариант функции <span class="math">\(J\)</span>, который мы можем использовать – MSE (тут непрятный вопрос, почему). Соответственно, задача настройки может быть переформулирована как задача минимизации значения целевой функции на заданном наборе входных данных.</p>
<p>Функция <span class="math">\(f\)</span> нам неизвестна, известен лишь набор её значений в некоторых точках (то бишь примеры входных данных и правильных ответов для них). Поэтому подгоняться веса сети будут так, чтобы приблизить значения функции в известных нам точках.</p>
<h3 id="метод-градиентного-спуска">Метод градиентного спуска</h3>
<ol style="list-style-type: decimal">
<li>Имеется задача оптимизации: найти <span class="math">\(\mathrm{arg\,min}_X F(x)\)</span>. Решение: возьмём какую-нибудь точку <span class="math">\(x_0 \in X\)</span> и пойдём в направлении наискорейшего спуска из этой точки <span class="math">\(x_{n+1} = x_n - \lambda_n \nabla F(x_n)\)</span></li>
<li>Прикидка идеи на сеть. Для того, чтобы сделать один шаг градиентного спуска, нужно посчитать производные целевой функции по всем весам сети. Для среднеквадратичной ошибки в качестве целевой функции <span class="math">\[J(\theta) = \frac{1}{2}\cdot\frac{1}{N}\sum_{k=1}^N \left\Vert \hat y_k - y_k \right\Vert ^2\]</span> производная будет выглядеть как <span class="math">\[\frac{\partial J}{\partial w_{ij}^l} = \frac{1}{N} \sum_{k=1}^N \sum_{i=1}^{n_L}\frac{\partial}{\partial w_{ij}^l} \left( \hat y_{ki} - y_{ki} \right),\]</span> то есть сумма производных для всех входов. То есть для одого шага градиентного спуска нужно пройти по всем данным. Данных может быть ОЧЕНЬ много, так что это не вариант.</li>
<li>Стохастический градиентный спуск: выбираем случайное подмножество наблюдений (как вариант, одно случайное наблюдение), считаем производную целевой функции для него и сдвигаемся в направлении антиградиента для этого конкретного наблюдения. <br>Теорема: если градиент целевой функции ограничен, минус градиент в среднем указывает в сторону минимума и градиент не равен нулю не в точке оптимума, то стохастический градиентный спуск сойдётся к оптимальному значению. <span class="citation">(Powell 2007)</span></li>
</ol>
<p>Заметим, что “градиент не равен нулю не в точке оптимума” – это очень сильное условие. Это означает, что никаких локальных минимумов/максимумов, никаких сёдел и уж тем более частично постоянных функций.</p>
<h3 id="алгоритм-обратного-распространения-ошибки">Алгоритм обратного распространения ошибки</h3>
<p>Самый важный вопрос: как считать-то этот градиент? Ответ: аналитически.</p>
<p>Пусть <span class="math">\(J(\theta)\)</span> – наша целевая функция, значение которой на множестве примеров <span class="math">\(\{x_i\}_{i=1}^N\)</span> мы хотим минимизировать по множеству параметров <span class="math">\(\theta\)</span>. Тогда для каждого параметра <span class="math">\(w_ {ij}^l\)</span> нужно посчитать <span class="math">\[\frac{\partial J}{\partial w_{ij}^l} = \frac{\partial J}{\partial a_i^l} \cdot \frac{\mathrm{d} a_i^l}{\mathrm{d} x} a^{l-1}_j.\]</span> Мы уже видим повторяющийся элемент <span class="math">\(\frac{\partial J}{\partial a^l_i}\)</span>, но из чего же состоит он сам? Из <span class="math">\[\frac{\partial J}{\partial a^l_i} = \sum_{m=1}^{n_{l+1}} \frac{\partial J}{\partial a^{l+1}_m}\cdot\frac{\mathrm{d} a^{l+1}_m}{\mathrm{d} x} w^{l+1}_{mj}.\]</span> То есть для того, чтобы посчитать производные на следующем слое, достаточно производные на предыдущем слое (уже неизбежно подсчитанные) умножить на известные константы.</p>
<p>Изложенное выше не включает в себя векторизацию, после которой формулы становятся красивее, но которая утомительнее в выписывании.</p>
<p>Подробное изложение с векторизацией см. в <span class="citation">(Nielsen 2015)</span></p>
<h2 id="примеры-неглубоких-сетей">Примеры неглубоких сетей</h2>
<h3 id="autoencoder">Autoencoder</h3>
<!-- ![схема автокодировщика](https://upload.wikimedia.org/wikipedia/commons/3/34/%D0%90%D0%B2%D1%82%D0%BE%D1%8D%D0%BD%D0%BA%D0%BE%D0%B4%D0%B5%D1%80.png)
 -->
<p>Пусть данные описываются векторами размера <span class="math">\(N&gt;&gt;1\)</span>. Мы хотим получить их представление размерности <span class="math">\(k\)</span>, для чего строим полносвязную нейронную сеть с одним внутренним слоем ширины <span class="math">\(k\)</span> и выходным слоем ширины <span class="math">\(N\)</span>. После чего обучаем сеть на множестве примеров, у которых правильный ответ для примера равен самому примеру. Тогда когда мы остановим обучение сети, у нас будет представление наших данных в пространстве меньшей размерности. Причём качество этого представления мы сможем измерить.</p>
<ul>
<li>как универсальный кодировщик эта идея не заходит, т.к. является репрезентативной только внутри поданной ей выборки, плохо обобщается</li>
<li>хорошо заходит в качестве очищения от шума (всё равно мы не знаем, что в данных было шумом)</li>
<li>использовалась для предобучения слоёв в глубинных сетях, но residual networks победили её всухую</li>
<li>говорят, что учит фичи лучше, чем PCA</li>
</ul>
<p><a href="https://blog.keras.io/building-autoencoders-in-keras.html">tutorial with lots of info</a> – хорошее введение с примерами приложений и бесполезностей</p>
<h3 id="word2vec">Word2Vec</h3>
<p><a href="https://arxiv.org/abs/1301.3781">Efficient Estimation of Word Representations in Vector Space</a> <a href="https://www.tensorflow.org/versions/r0.10/tutorials/word2vec/index.html">Tutorial with net scheme and more on embeddings themselves</a></p>
<h2 id="проблемы">Проблемы</h2>
<p>Нейросети требовательны к объёму памяти и скорости вычислений, не очень хорошо параллелятся и т.д. При увеличении количества слоёв появляются проблемы с “размазыванием” градиента и с точностью вычислений. Не все данные представимы конечным разумным числом входов (см. “Картинки с большим разрешением”, “текстовые последовательности”, считай требуемую память, умирай). Не гарантируется скорость сходимости, поэтому хочется задавать априорную информацию о структуре взаимоотношений между входами.</p>
<h2 id="решения">Решения</h2>
<h3 id="convolutional-neural-networks">Convolutional neural networks</h3>
<p><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">wiki</a> find proper literature and pictures</p>
<h3 id="local-vs.global-optimization">Local vs. global optimization</h3>
<p>what the hell does it mean and why did I write this?</p>
<h3 id="optional-recurrent-neural-networks">[optional] Recurrent neural networks</h3>
<p>??? whatever else</p>
<div class="references">
<p>Nielsen, Michael A. 2015. <em>Neural Networks and Deep Learning</em>. Determination Press. <a href="http://neuralnetworksanddeeplearning.com" class="uri">http://neuralnetworksanddeeplearning.com</a>.</p>
<p>Powell, Warren B. 2007. “Approximate Dynamic Programming: Solving the Curses of Dimensionality.” John Wiley &amp; Sons.</p>
<p>Воронцов, Константин Вячеславович. 2007. “Лекции По Искусственным Нейронным Сетям,” 102–12. <a href="http://www.ccas.ru/voron/download/NeuralNets.pdf" class="uri">http://www.ccas.ru/voron/download/NeuralNets.pdf</a>.</p>
<p>———. 2011. <em>Математические Методы Обучения По Прецедентам (Теория Обучения Машин)</em>. <a href="http://www.machinelearning.ru/wiki/images/6/6d/voron-ml-1.pdf" class="uri">http://www.machinelearning.ru/wiki/images/6/6d/voron-ml-1.pdf</a>.</p>
<p>Горбань, А.Н., В.Л. Дунин-Барковский, А.Н. Кирдин, and others. 1998. <em>Нейроинформатика</em>. Новосибирск: Наука. <a href="http://ict.edu.ru/ft/003873/neiro.pdf" class="uri">http://ict.edu.ru/ft/003873/neiro.pdf</a>.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Слова “нейрон” и “перцептрон” не являются взаимозаменяемыми. Нейроны могут иметь иной вид (см. <a href="https://en.wikipedia.org/wiki/Long_short-term_memory">LSTM</a>), перцептрон — конкретный подвид нейрона.<a href="#fnref1">↩</a></p></li>
</ol>
</div>
</body>
</html>
