<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Анастасия Миллер" />
  <title>Нейронные сети: принципы, проблемы, что работает, что нет и почему.</title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<div id="header">
<h1 class="title"><p>Нейронные сети: принципы, проблемы, что работает, что нет и почему.</p></h1>
<h2 class="author">Анастасия Миллер</h2>
</div>
<p>NB: всё далее изложенное – черновик черновика текста доклада, здесь могут быть принципиально неверные утверждения и фактические ошибки. План чистки:</p>
<ol style="list-style-type: decimal">
<li>Написать черновое содержание (весь текст, что есть в голове, всё “я придумаю, как сказать об этой формуле” – придумать и записать сюда). По ходу отмечать, где не достаёт ссылок и точных формулировок и где возможны фактические неточности.</li>
<li>Пройтись по отметкам, найти ссылки, исправить формулировки и переписать текст с учётом новых данных. Проверить получившийся текст на связность, достаточность ссылок и точность формулировок. Если проверка не пройдена, перейти в 2.</li>
<li>Перечитать текст и склепать по нему презентацию.</li>
<li>Проверить презентацию на связность и внутреннюю логику. Если проверка не пройдена, перейти в 2.</li>
<li>PROFIT.</li>
</ol>
<h2 id="optional-про-мозг-передача-информации-путём-активации-нейронов.">[optional] Про мозг: передача информации путём активации нейронов.</h2>
<p>Блаблабла, придумать текст</p>
<h2 id="архитектура-полносвязной-сети-и-передача-информации-в-ней.">Архитектура полносвязной сети и передача информации в ней.</h2>
<p>Сначала поговорим про организацию нейросети как системы передачи информации. Идея в следующем: имеется вот такая картинка</p>
<div class="figure">
<img src="abstract_net_example.png" alt="изображение абстрактной нейронной сети" />
<p class="caption">изображение абстрактной нейронной сети</p>
</div>
<p>Для каждого узла сети есть своя сумматорная функция z и своя активационная функция a. На первом слое есть только активационная функция — <span class="math"><em>a</em><sub><em>i</em></sub>(<em>x</em>) = <em>x</em></span>. Входные данные подаются как аргументы активационных функций первого слоя. Обычно сумматорная функция в узлах — просто взвешенная сумма значений активационных функций узлов предыдущего слоя, связанных с этим. Значением, вычисленным нейронной сетью, считается вектор из значений активационных функций узлов последнего (выходного) слоя. То есть получаем «рекурсивно» определённую функцию:</p>
<p><br /><span class="math"><em>a</em><sub><em>i</em></sub><sup>1</sup> = <code>i</code><code>n</code><code>p</code><code>u</code><code>t</code><code>[</code><em>i</em><code>]</code></span><br /> <br /><span class="math"><em>a</em><sub><em>i</em></sub><sup><em>l</em></sup> = <em>a</em><sub><em>i</em></sub><sup><em>l</em></sup>(<em>z</em><sub><em>i</em></sub><sup><em>l</em></sup>) = <em>a</em><sub><em>i</em></sub><sup><em>l</em></sup>(∑<sub><em>j</em></sub><em>w</em><sub><em>i</em><em>j</em></sub><sup><em>l</em></sup><em>a</em><sub><em>j</em></sub><sup><em>l</em> − 1</sup>)</span><br /></p>
<p>(здесь я уже подставила обычную суммирующую функцию). Активационная функция может быть какой угодно, обычно выбирается в зависимости от требований к области значений ответов: на внутренних слоях сигмоида, на наружных — сигмоида, арктангенс или ReLU. Почему такие — сейчас скажем.</p>
<p>Идея, стоящая за созданием нейронных сетей, заключается в том, чтобы промоделировать работу человеческого мозга. Очень общее и условное представление об устройстве и работе клетки человеческого мозга и легло в основу математической модели “нейронная сеть”. Естественный нейрон в коре головного мозга, согласно этому представлению, выглядит следующим образом:</p>
<p>Клетка имеет множество разветвлённых отростков — дендритов, и одно длинное тонкое волокно — аксон, на конце которого находятся синапсы, примыкающие к дендритам других нервных клеток. Каждая нервная клетка может находиться в двух состояниях: обычном и возбуждённом. В возбуждённом состоянии клетка генерирует электрический импульс, который проходит по аксону до синапсов. Синапс при приходе импульса выделяет вещество, способствующее проникновению положительных зарядов внутрь соседней клетки. Синапсы имеют разную способность концентрировать это вещество, некоторые даже препятствуют его выделению — они называются тормозящими. Если суммарный заряд, попавший в клетку, превосходит некоторый порог, клетка возбуждается и генерирует импульс, который распространяется по аксону и доходит до синапсов, что способствует возбуждению следующих клеток. После возбуждения клетки наступает период релаксации — некоторое время она не способна генерировать новые импульсы. Благодаря этому клетки работают по тактам, наподобие дискретных автоматов, а сеть в целом передаёт направленную волну импульсов. <span class="citation">(КВ Воронцов)</span></p>
<p>Математическая модель естественного нейрона тогда выглядит следующим образом ( модель МакКаллока-Питтса): <span class="math"><em>a</em>(<em>x</em><sub>1</sub>, …<em>x</em><sub><em>n</em><sub><em>l</em> − 1</sub></sub>) = <em>s</em><em>i</em><em>g</em><em>n</em>(∑<em>x</em><sub><em>i</em></sub> + <em>b</em>)</span>, где <span class="math"><em>x</em><sub><em>i</em></sub></span> — значения входов для этого нейрона.</p>
<p>Обобщая эту конструкцию, получаем систему, которую мы видели на первой картинке: <br /><span class="math"><em>a</em><sub><em>i</em></sub><sup><em>l</em></sup> = <em>a</em><sub><em>i</em></sub><sup><em>l</em></sup>(∑<sub><em>j</em></sub><em>w</em><sub><em>i</em><em>j</em></sub><sup><em>l</em></sup><em>a</em><sub><em>j</em></sub><sup><em>l</em> − 1</sup>)</span><br /></p>
<h3 id="нейронная-сеть-универсальный-аппроксиматор">Нейронная сеть – универсальный аппроксиматор</h3>
<p>Давайте теперь детально поговорим о том, какие именно функции нейросеть теоретически может вычислить. <span class="citation">(К.В. Воронцов 2011)</span></p>
<p>Опр.: Набор функций <span class="math"><em>F</em> ⊂ <em>C</em>(<em>X</em>)</span> называется замкнутым относительно функции <span class="math"><em>ϕ</em> : ℝ → ℝ</span>, если для любого <span class="math"><em>f</em> ∈ <em>F</em></span> выполнено <span class="math"><em>ϕ</em>(<em>f</em>) ∈ <em>F</em></span>.</p>
<p>Т. (Горбань, 1998): Пусть <span class="math"><em>X</em></span> — компактное пространство, <span class="math"><em>C</em>(<em>X</em>)</span> — алгебра непрерывных на <span class="math"><em>X</em></span> вещественных функций, <span class="math"><em>F</em></span> — линейное подпространство в <span class="math"><em>C</em>(<em>X</em>)</span>, замкнутое относительно нелинейной непрерывной функции <span class="math"><em>ϕ</em></span>, содержащее константу (<span class="math">1 ∈ <em>F</em></span>) и разделяющее точки множества <span class="math"><em>X</em></span>. Тогда <span class="math"><em>F</em></span> плотно в <span class="math"><em>C</em>(<em>X</em>)</span>.</p>
<p>То есть для любой функции <span class="math"><em>g</em> ∈ <em>C</em>(<em>X</em>)</span> можно взять одну нелинейную <span class="math"><em>ϕ</em></span> и суперпозицией её линейных комбинаций (которой и является нейросеть, если у всех нейронов активационные функции одинаковы) приблизить <span class="math"><em>g</em></span> с любой заданной точностью. Проблема только в том, что теорема не говорит, как именно это сделать</p>
<h2 id="задача-обучения-сети">Задача обучения сети</h2>
<p>Пусть мы хотим научиться приближать функцию <span class="math">$f: \mathbb R^N \to \mathbb R^k$</span> нейронной сетью заданной архитектуры (с фиксированным количеством слоёв, нейронов на слоях и сумматорных и активационных функций в этих нейронах). Функция, вычисляемая сетью при зафиксированной архитектуре сети, зависит только от множества её весов. То есть в общем случае задача настройки весов сети заключается в том, чтобы найти набор весов <span class="math"><em>w</em><sub><em>i</em><em>j</em></sub><sup><em>l</em></sup> = <em>a</em><em>r</em><em>g</em> <em>m</em><em>i</em><em>n</em><em>w</em><sub><em>i</em><em>j</em></sub><sup><em>l</em></sup><em>J</em>(<em>f</em>, <em>a</em>(<em>w</em><sub><em>i</em><em>j</em></sub><sup><em>l</em></sup>))</span>.</p>
<p>Качество обучения сети оценивается функцией ошибок. Самый простой вариант – MSE. Соответственно, задача настройки может быть переформулирована как задача минимизации значения целевой функции на заданном наборе входных данных.</p>
<p>Функция <span class="math"><em>f</em></span> нам неизвестна, известен лишь набор её значений в некоторых точках (то бишь примеры входных данных и правильных ответов для них). Поэтому подгоняться веса сети будут так, чтобы приблизить значения функции в известных нам точках.</p>
<p>Здесь можно отвлечься и показать, что вообще-то задача “найти функцию, принимающую заданные значения в заданных точках” может быть решена с помощью полиномов. И если у нас есть 100 точек, то полином сотой степени зайдёт, но только это дорого в плане ресурсов (с примером подсчёта ресурсов).</p>
<h3 id="метод-градиентного-спуска">Метод градиентного спуска</h3>
<ol style="list-style-type: decimal">
<li>Идея детерминированного метода</li>
<li>Прикидка идеи на сеть. Для того, чтобы сделать один шаг градиентного спуска, нужно посчитать производные целевой функции по всем весам сети. Производная целевой функции в случае, например, MSE – это <span class="math">$\frac{1}{N}\sum_{k=1}^N\frac{\partial}{\partial w_{ij}^l} \left( \hat y_k - y_k \right)$</span>, то есть сумма производных для всех входов. То есть для одого шага градиентного спуска нужно пройти по всем данным. Данных может быть ОЧЕНЬ много, так что это не вариант.</li>
<li>Стохастический градиентный спуск: выбираем случайное подмножество наблюдений (как вариант, одно случайное наблюдение), считаем производную целевой функции для него и сдвигаемся в направлении антиградиента для этого конкретного наблюдения. <br>Теорема: если градиент целевой функции ограничен, минус градиент в среднем указывает в сторону минимума и градиент не равен нулю не в точке оптимума, то стохастический градиентный спуск сойдётся к оптимальному значению. <span class="citation">(Powell 2007)</span></li>
</ol>
<p>Заметим, что “градиент не равен нулю не в точке оптимума” – это очень сильное условие. Это означает, что никаких локальных минимумов/максимумов, никаких сёдел и уж тем более частично постоянных функций.</p>
<h3 id="алгоритм-обратного-распространения-ошибки">Алгоритм обратного распространения ошибки</h3>
<p>Самый важный вопрос: как считать-то этот градиент? Ответ: аналитически.</p>
<p>Пусть <span class="math"><em>J</em>(<em>θ</em>)</span> – наша целевая функция, значение которой на множестве примеров <span class="math"><em>x</em><sub><em>i</em></sub><sub><em>i</em> = 1</sub><sup><em>N</em></sup></span> мы хотим минимизировать по множеству параметров <span class="math"><em>θ</em></span>. Тогда для каждого параметра <span class="math"><em>w</em><sub><em>i</em><em>j</em></sub><sup><em>l</em></sup></span> нужно посчитать <br /><span class="math">$$\frac{\partial J}{\partial w_{ij}^l} = \frac{\partial J}{\partial a_i^l}\cdot \frac{\mathrm d a_i^l}{\mathrm d x} a^{l-1}_j$$</span><br />. Мы уже видим повторяющийся элемент <span class="math">$\frac{\partial J}{\partial a^l_i}$</span>, но из чего же состоит он сам? Из <br /><span class="math">$$\frac{\partial J}{\partial a^l_i} = \sum_{m=1}^{n_{l+1}} \frac{\partial J}{\partial a^{l+1}_m}\cdot\frac{\mathrm d a^{l+1}_m}{\mathrm d x} w^{l+1}_{mj}$$</span><br />. То есть для того, чтобы посчитать производные на следующем слое, достаточно производные на предыдущем слое (уже неизбежно подсчитанные) умножить на известные константы.</p>
<p>Изложенное выше не включает в себя векторизацию, после которой формулы становятся красивее, но которая утомительнее в выписывании.</p>
<p>Подробное изложение с векторизацией см. В <span class="citation">(Nielsen 2015)</span></p>
<h2 id="примеры-неглубоких-сетей">Примеры неглубоких сетей</h2>
<h3 id="autoencoder">Autoencoder</h3>
<h3 id="word2vec">Word2Vec</h3>
<h2 id="проблемы">Проблемы</h2>
<p>Нейросети требовательны к объёму памяти и скорости вычислений, не очень хорошо параллелятся и т.д. При увеличении количества слоёв (зачем увеличивать, если можно расширить, ведь теорема об универсальном аппроксиматоре говорит расширять, а не растить? Выяснить) появляются проблемы с “размазыванием” градиента и с точностью вычислений. Не все данные представимы конечным разумным числом входов (см. “Картинки с большим разрешением”, “текстовые последовательности”, считай требуемую память, умирай). Не гарантируется скорость сходимости, поэтому хочется задавать априорную информацию о структуре взаимоотношений между входами. ## Решения ### Convolutional neural networks ### Local vs. global optimization ### [optional] Recurrent neural networks</p>
<p>??? whatever else</p>
<div class="references">
<p>Nielsen, Michael A. 2015. <em>Neural Networks and Deep Learning</em>. Determination Press.</p>
<p>Powell, Warren B. 2007. “Approximate Dynamic Programming: Solving the Curses of Dimensionality.” John Wiley &amp; Sons.</p>
<p>Воронцов, К.В. 2011. “Математические Методы Обучения По Прецедентам (Теория Обучения Машин),” 102–12. <a href="http://www.machinelearning.ru/wiki/images/6/6d/voron-ml-1.pdf" class="uri">http://www.machinelearning.ru/wiki/images/6/6d/voron-ml-1.pdf</a>.</p>
<p>Воронцов, КВ. “Лекции По Искусственным Нейронным Сетям.” <a href="http://www.ccas.ru/voron/download/NeuralNets.pdf" class="uri">http://www.ccas.ru/voron/download/NeuralNets.pdf</a>.</p>
</div>
</body>
</html>
