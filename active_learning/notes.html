<!DOCTYPE html>
<html>
  <head>
      <meta charset="utf-8" />
      <title>notes</title>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX","output/HTML-CSS"],
    extensions: [],
    TeX: {
      extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
    },
    showMathMenu: false
  });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js">
</script>
      <style>.markdown-preview:not([data-use-github-style]) { padding: 2em; font-size: 1.2em; color: rgb(29, 31, 33); overflow: auto; background-color: rgb(255, 255, 255); }
.markdown-preview:not([data-use-github-style]) > :first-child { margin-top: 0px; }
.markdown-preview:not([data-use-github-style]) h1, .markdown-preview:not([data-use-github-style]) h2, .markdown-preview:not([data-use-github-style]) h3, .markdown-preview:not([data-use-github-style]) h4, .markdown-preview:not([data-use-github-style]) h5, .markdown-preview:not([data-use-github-style]) h6 { line-height: 1.2; margin-top: 1.5em; margin-bottom: 0.5em; color: rgb(0, 0, 0); }
.markdown-preview:not([data-use-github-style]) h1 { font-size: 2.4em; font-weight: 300; }
.markdown-preview:not([data-use-github-style]) h2 { font-size: 1.8em; font-weight: 400; }
.markdown-preview:not([data-use-github-style]) h3 { font-size: 1.5em; font-weight: 500; }
.markdown-preview:not([data-use-github-style]) h4 { font-size: 1.2em; font-weight: 600; }
.markdown-preview:not([data-use-github-style]) h5 { font-size: 1.1em; font-weight: 600; }
.markdown-preview:not([data-use-github-style]) h6 { font-size: 1em; font-weight: 600; }
.markdown-preview:not([data-use-github-style]) strong { color: rgb(0, 0, 0); }
.markdown-preview:not([data-use-github-style]) del { color: rgb(67, 72, 76); }
.markdown-preview:not([data-use-github-style]) a, .markdown-preview:not([data-use-github-style]) a code { color: rgb(29, 31, 33); }
.markdown-preview:not([data-use-github-style]) img { max-width: 100%; }
.markdown-preview:not([data-use-github-style]) > p { margin-top: 0px; margin-bottom: 1.5em; }
.markdown-preview:not([data-use-github-style]) > ul, .markdown-preview:not([data-use-github-style]) > ol { margin-bottom: 1.5em; }
.markdown-preview:not([data-use-github-style]) blockquote { margin: 1.5em 0px; font-size: inherit; color: rgb(67, 72, 76); border-color: rgb(214, 214, 214); border-width: 4px; }
.markdown-preview:not([data-use-github-style]) hr { margin: 3em 0px; border-top: 2px dashed rgb(214, 214, 214); background: none; }
.markdown-preview:not([data-use-github-style]) table { margin: 1.5em 0px; }
.markdown-preview:not([data-use-github-style]) th { color: rgb(0, 0, 0); }
.markdown-preview:not([data-use-github-style]) th, .markdown-preview:not([data-use-github-style]) td { padding: 0.66em 1em; border: 1px solid rgb(214, 214, 214); }
.markdown-preview:not([data-use-github-style]) pre, .markdown-preview:not([data-use-github-style]) code { color: rgb(0, 0, 0); background-color: rgb(240, 240, 240); }
.markdown-preview:not([data-use-github-style]) pre, .markdown-preview:not([data-use-github-style]) pre.editor-colors { margin: 1.5em 0px; padding: 1em; font-size: 0.92em; border-radius: 3px; background-color: rgb(245, 245, 245); }
.markdown-preview:not([data-use-github-style]) kbd { color: rgb(0, 0, 0); border-width: 1px 1px 2px; border-style: solid; border-color: rgb(214, 214, 214) rgb(214, 214, 214) rgb(199, 199, 199); background-color: rgb(240, 240, 240); }
.markdown-preview[data-use-github-style] { font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif; line-height: 1.6; word-wrap: break-word; padding: 30px; font-size: 16px; color: rgb(51, 51, 51); overflow: scroll; background-color: rgb(255, 255, 255); }
.markdown-preview[data-use-github-style] > :first-child { margin-top: 0px !important; }
.markdown-preview[data-use-github-style] > :last-child { margin-bottom: 0px !important; }
.markdown-preview[data-use-github-style] a:not([href]) { color: inherit; text-decoration: none; }
.markdown-preview[data-use-github-style] .absent { color: rgb(204, 0, 0); }
.markdown-preview[data-use-github-style] .anchor { position: absolute; top: 0px; left: 0px; display: block; padding-right: 6px; padding-left: 30px; margin-left: -30px; }
.markdown-preview[data-use-github-style] .anchor:focus { outline: none; }
.markdown-preview[data-use-github-style] h1, .markdown-preview[data-use-github-style] h2, .markdown-preview[data-use-github-style] h3, .markdown-preview[data-use-github-style] h4, .markdown-preview[data-use-github-style] h5, .markdown-preview[data-use-github-style] h6 { position: relative; margin-top: 1em; margin-bottom: 16px; font-weight: bold; line-height: 1.4; }
.markdown-preview[data-use-github-style] h1 .octicon-link, .markdown-preview[data-use-github-style] h2 .octicon-link, .markdown-preview[data-use-github-style] h3 .octicon-link, .markdown-preview[data-use-github-style] h4 .octicon-link, .markdown-preview[data-use-github-style] h5 .octicon-link, .markdown-preview[data-use-github-style] h6 .octicon-link { display: none; color: rgb(0, 0, 0); vertical-align: middle; }
.markdown-preview[data-use-github-style] h1:hover .anchor, .markdown-preview[data-use-github-style] h2:hover .anchor, .markdown-preview[data-use-github-style] h3:hover .anchor, .markdown-preview[data-use-github-style] h4:hover .anchor, .markdown-preview[data-use-github-style] h5:hover .anchor, .markdown-preview[data-use-github-style] h6:hover .anchor { padding-left: 8px; margin-left: -30px; text-decoration: none; }
.markdown-preview[data-use-github-style] h1:hover .anchor .octicon-link, .markdown-preview[data-use-github-style] h2:hover .anchor .octicon-link, .markdown-preview[data-use-github-style] h3:hover .anchor .octicon-link, .markdown-preview[data-use-github-style] h4:hover .anchor .octicon-link, .markdown-preview[data-use-github-style] h5:hover .anchor .octicon-link, .markdown-preview[data-use-github-style] h6:hover .anchor .octicon-link { display: inline-block; }
.markdown-preview[data-use-github-style] h1 tt, .markdown-preview[data-use-github-style] h2 tt, .markdown-preview[data-use-github-style] h3 tt, .markdown-preview[data-use-github-style] h4 tt, .markdown-preview[data-use-github-style] h5 tt, .markdown-preview[data-use-github-style] h6 tt, .markdown-preview[data-use-github-style] h1 code, .markdown-preview[data-use-github-style] h2 code, .markdown-preview[data-use-github-style] h3 code, .markdown-preview[data-use-github-style] h4 code, .markdown-preview[data-use-github-style] h5 code, .markdown-preview[data-use-github-style] h6 code { font-size: inherit; }
.markdown-preview[data-use-github-style] h1 { padding-bottom: 0.3em; font-size: 2.25em; line-height: 1.2; border-bottom: 1px solid rgb(238, 238, 238); }
.markdown-preview[data-use-github-style] h1 .anchor { line-height: 1; }
.markdown-preview[data-use-github-style] h2 { padding-bottom: 0.3em; font-size: 1.75em; line-height: 1.225; border-bottom: 1px solid rgb(238, 238, 238); }
.markdown-preview[data-use-github-style] h2 .anchor { line-height: 1; }
.markdown-preview[data-use-github-style] h3 { font-size: 1.5em; line-height: 1.43; }
.markdown-preview[data-use-github-style] h3 .anchor { line-height: 1.2; }
.markdown-preview[data-use-github-style] h4 { font-size: 1.25em; }
.markdown-preview[data-use-github-style] h4 .anchor { line-height: 1.2; }
.markdown-preview[data-use-github-style] h5 { font-size: 1em; }
.markdown-preview[data-use-github-style] h5 .anchor { line-height: 1.1; }
.markdown-preview[data-use-github-style] h6 { font-size: 1em; color: rgb(119, 119, 119); }
.markdown-preview[data-use-github-style] h6 .anchor { line-height: 1.1; }
.markdown-preview[data-use-github-style] p, .markdown-preview[data-use-github-style] blockquote, .markdown-preview[data-use-github-style] ul, .markdown-preview[data-use-github-style] ol, .markdown-preview[data-use-github-style] dl, .markdown-preview[data-use-github-style] table, .markdown-preview[data-use-github-style] pre { margin-top: 0px; margin-bottom: 16px; }
.markdown-preview[data-use-github-style] hr { height: 4px; padding: 0px; margin: 16px 0px; border: 0px none; background-color: rgb(231, 231, 231); }
.markdown-preview[data-use-github-style] ul, .markdown-preview[data-use-github-style] ol { padding-left: 2em; }
.markdown-preview[data-use-github-style] ul.no-list, .markdown-preview[data-use-github-style] ol.no-list { padding: 0px; list-style-type: none; }
.markdown-preview[data-use-github-style] ul ul, .markdown-preview[data-use-github-style] ul ol, .markdown-preview[data-use-github-style] ol ol, .markdown-preview[data-use-github-style] ol ul { margin-top: 0px; margin-bottom: 0px; }
.markdown-preview[data-use-github-style] li > p { margin-top: 16px; }
.markdown-preview[data-use-github-style] dl { padding: 0px; }
.markdown-preview[data-use-github-style] dl dt { padding: 0px; margin-top: 16px; font-size: 1em; font-style: italic; font-weight: bold; }
.markdown-preview[data-use-github-style] dl dd { padding: 0px 16px; margin-bottom: 16px; }
.markdown-preview[data-use-github-style] blockquote { padding: 0px 15px; color: rgb(119, 119, 119); border-left: 4px solid rgb(221, 221, 221); }
.markdown-preview[data-use-github-style] blockquote > :first-child { margin-top: 0px; }
.markdown-preview[data-use-github-style] blockquote > :last-child { margin-bottom: 0px; }
.markdown-preview[data-use-github-style] table { display: block; width: 100%; overflow: auto; word-break: keep-all; }
.markdown-preview[data-use-github-style] table th { font-weight: bold; }
.markdown-preview[data-use-github-style] table th, .markdown-preview[data-use-github-style] table td { padding: 6px 13px; border: 1px solid rgb(221, 221, 221); }
.markdown-preview[data-use-github-style] table tr { border-top: 1px solid rgb(204, 204, 204); background-color: rgb(255, 255, 255); }
.markdown-preview[data-use-github-style] table tr:nth-child(2n) { background-color: rgb(248, 248, 248); }
.markdown-preview[data-use-github-style] img { max-width: 100%; box-sizing: border-box; }
.markdown-preview[data-use-github-style] .emoji { max-width: none; }
.markdown-preview[data-use-github-style] span.frame { display: block; overflow: hidden; }
.markdown-preview[data-use-github-style] span.frame > span { display: block; float: left; width: auto; padding: 7px; margin: 13px 0px 0px; overflow: hidden; border: 1px solid rgb(221, 221, 221); }
.markdown-preview[data-use-github-style] span.frame span img { display: block; float: left; }
.markdown-preview[data-use-github-style] span.frame span span { display: block; padding: 5px 0px 0px; clear: both; color: rgb(51, 51, 51); }
.markdown-preview[data-use-github-style] span.align-center { display: block; overflow: hidden; clear: both; }
.markdown-preview[data-use-github-style] span.align-center > span { display: block; margin: 13px auto 0px; overflow: hidden; text-align: center; }
.markdown-preview[data-use-github-style] span.align-center span img { margin: 0px auto; text-align: center; }
.markdown-preview[data-use-github-style] span.align-right { display: block; overflow: hidden; clear: both; }
.markdown-preview[data-use-github-style] span.align-right > span { display: block; margin: 13px 0px 0px; overflow: hidden; text-align: right; }
.markdown-preview[data-use-github-style] span.align-right span img { margin: 0px; text-align: right; }
.markdown-preview[data-use-github-style] span.float-left { display: block; float: left; margin-right: 13px; overflow: hidden; }
.markdown-preview[data-use-github-style] span.float-left span { margin: 13px 0px 0px; }
.markdown-preview[data-use-github-style] span.float-right { display: block; float: right; margin-left: 13px; overflow: hidden; }
.markdown-preview[data-use-github-style] span.float-right > span { display: block; margin: 13px auto 0px; overflow: hidden; text-align: right; }
.markdown-preview[data-use-github-style] code, .markdown-preview[data-use-github-style] tt { padding: 0.2em 0px; margin: 0px; font-size: 85%; border-radius: 3px; background-color: rgba(0, 0, 0, 0.0392157); }
.markdown-preview[data-use-github-style] code::before, .markdown-preview[data-use-github-style] tt::before, .markdown-preview[data-use-github-style] code::after, .markdown-preview[data-use-github-style] tt::after { letter-spacing: -0.2em; content: " "; }
.markdown-preview[data-use-github-style] code br, .markdown-preview[data-use-github-style] tt br { display: none; }
.markdown-preview[data-use-github-style] del code { text-decoration: inherit; }
.markdown-preview[data-use-github-style] pre > code { padding: 0px; margin: 0px; font-size: 100%; word-break: normal; white-space: pre; border: 0px; background: transparent; }
.markdown-preview[data-use-github-style] .highlight { margin-bottom: 16px; }
.markdown-preview[data-use-github-style] .highlight pre, .markdown-preview[data-use-github-style] pre { padding: 16px; overflow: auto; font-size: 85%; line-height: 1.45; border-radius: 3px; background-color: rgb(247, 247, 247); }
.markdown-preview[data-use-github-style] .highlight pre { margin-bottom: 0px; word-break: normal; }
.markdown-preview[data-use-github-style] pre { word-wrap: normal; }
.markdown-preview[data-use-github-style] pre code, .markdown-preview[data-use-github-style] pre tt { display: inline; max-width: initial; padding: 0px; margin: 0px; overflow: initial; line-height: inherit; word-wrap: normal; border: 0px; background-color: transparent; }
.markdown-preview[data-use-github-style] pre code::before, .markdown-preview[data-use-github-style] pre tt::before, .markdown-preview[data-use-github-style] pre code::after, .markdown-preview[data-use-github-style] pre tt::after { content: normal; }
.markdown-preview[data-use-github-style] kbd { display: inline-block; padding: 3px 5px; font-size: 11px; line-height: 10px; color: rgb(85, 85, 85); vertical-align: middle; border-width: 1px; border-style: solid; border-color: rgb(204, 204, 204) rgb(204, 204, 204) rgb(187, 187, 187); border-radius: 3px; box-shadow: rgb(187, 187, 187) 0px -1px 0px inset; background-color: rgb(252, 252, 252); }
.markdown-preview[data-use-github-style] a { color: rgb(51, 122, 183); }
.markdown-preview[data-use-github-style] pre, .markdown-preview[data-use-github-style] code { color: inherit; }
.markdown-preview[data-use-github-style] pre, .markdown-preview[data-use-github-style] pre.editor-colors { padding: 0.8em 1em; margin-bottom: 1em; font-size: 0.85em; border-radius: 4px; overflow: auto; }
.scrollbars-visible-always .markdown-preview pre.editor-colors::shadow .vertical-scrollbar, .scrollbars-visible-always .markdown-preview pre.editor-colors::shadow .horizontal-scrollbar { visibility: hidden; }
.scrollbars-visible-always .markdown-preview pre.editor-colors:hover::shadow .vertical-scrollbar, .scrollbars-visible-always .markdown-preview pre.editor-colors:hover::shadow .horizontal-scrollbar { visibility: visible; }
.markdown-preview del { text-decoration: none; position: relative; }
.markdown-preview del::after { border-bottom: 1px solid black; content: ""; left: 0px; position: absolute; right: 0px; top: 50%; }
.markdown-preview .flash { animation: flash 1s ease-out 1; outline: rgba(255, 0, 0, 0) solid 1px; }
.markdown-preview .flash:not(li) { display: block; }
.bracket-matcher .region {
  border-bottom: 1px dotted lime;
  position: absolute;
}

.spell-check-misspelling .region {
  border-bottom: 2px dotted rgba(255, 51, 51, 0.75);
}
.spell-check-corrections {
  width: 25em !important;
}

pre.editor-colors,
.host {
  background-color: #ffffff;
  color: #1d1f21;
}
pre.editor-colors .wrap-guide,
.host .wrap-guide {
  background-color: #c5c8c6;
}
pre.editor-colors .indent-guide,
.host .indent-guide {
  color: #c5c8c6;
}
pre.editor-colors .invisible-character,
.host .invisible-character {
  color: #c5c8c6;
}
pre.editor-colors .gutter,
.host .gutter {
  background-color: #ffffff;
  color: #b4b7b4;
}
pre.editor-colors .gutter .line-number,
.host .gutter .line-number {
  padding: 0 0.25em 0 0.5em;
  -webkit-font-smoothing: antialiased;
}
pre.editor-colors .gutter .line-number.cursor-line,
.host .gutter .line-number.cursor-line {
  background-color: #e0e0e0;
  color: #373b41;
}
pre.editor-colors .gutter .line-number.cursor-line-no-selection,
.host .gutter .line-number.cursor-line-no-selection {
  color: #373b41;
}
pre.editor-colors .gutter .line-number.folded,
.host .gutter .line-number.folded,
pre.editor-colors .gutter .line-number:after,
.host .gutter .line-number:after,
pre.editor-colors .fold-marker:after,
.host .fold-marker:after {
  color: #b4b7b4;
}
pre.editor-colors .invisible,
.host .invisible {
  color: #1d1f21;
}
pre.editor-colors .cursor,
.host .cursor {
  color: #1d1f21;
}
pre.editor-colors .selection .region,
.host .selection .region {
  background-color: #e0e0e0;
}
pre.editor-colors .bracket-matcher .region,
.host .bracket-matcher .region {
  border-color: #b4b7b4;
}
.comment {
  color: #969896;
}
.entity.name.type {
  color: #f0c674;
}
.entity.other.inherited-class {
  color: #b5bd68;
}
.keyword {
  color: #b294bb;
}
.keyword.control {
  color: #b294bb;
}
.keyword.operator {
  color: #1d1f21;
}
.keyword.other.special-method {
  color: #81a2be;
}
.keyword.other.unit {
  color: #de935f;
}
.storage {
  color: #b294bb;
}
.constant {
  color: #de935f;
}
.constant.character.escape {
  color: #8abeb7;
}
.constant.numeric {
  color: #de935f;
}
.constant.other.color {
  color: #8abeb7;
}
.constant.other.symbol {
  color: #b5bd68;
}
.variable {
  color: #cc6666;
}
.variable.interpolation {
  color: #a3685a;
}
.variable.parameter.function {
  color: #1d1f21;
}
.invalid.illegal {
  background-color: #cc6666;
  color: #ffffff;
}
.string {
  color: #b5bd68;
}
.string.regexp {
  color: #8abeb7;
}
.string.regexp .source.ruby.embedded {
  color: #f0c674;
}
.string.other.link {
  color: #cc6666;
}
.punctuation.definition.parameters,
.punctuation.definition.array {
  color: #1d1f21;
}
.punctuation.definition.heading,
.punctuation.definition.identity {
  color: #81a2be;
}
.punctuation.definition.bold {
  color: #f0c674;
  font-weight: bold;
}
.punctuation.definition.italic {
  color: #b294bb;
  font-style: italic;
}
.punctuation.section.embedded {
  color: #a3685a;
}
.punctuation.section.method,
.punctuation.section.class,
.punctuation.section.inner-class {
  color: #1d1f21;
}
.support.class {
  color: #f0c674;
}
.support.function {
  color: #8abeb7;
}
.support.function.any-method {
  color: #81a2be;
}
.entity.name.function {
  color: #81a2be;
}
.entity.name.class,
.entity.name.type.class {
  color: #f0c674;
}
.entity.name.section {
  color: #81a2be;
}
.entity.name.tag {
  color: #cc6666;
}
.entity.other.attribute-name {
  color: #de935f;
}
.entity.other.attribute-name.id {
  color: #81a2be;
}
.meta.class {
  color: #f0c674;
}
.meta.class.body {
  color: #1d1f21;
}
.meta.link {
  color: #de935f;
}
.meta.method-call,
.meta.method {
  color: #1d1f21;
}
.meta.require {
  color: #81a2be;
}
.meta.selector {
  color: #b294bb;
}
.meta.separator {
  background-color: #373b41;
  color: #1d1f21;
}
.meta.tag {
  color: #1d1f21;
}
.none {
  color: #1d1f21;
}
.markup.bold {
  color: #de935f;
  font-weight: bold;
}
.markup.changed {
  color: #b294bb;
}
.markup.deleted {
  color: #cc6666;
}
.markup.italic {
  color: #b294bb;
  font-style: italic;
}
.markup.heading {
  color: #cc6666;
}
.markup.heading .punctuation.definition.heading {
  color: #81a2be;
}
.markup.link {
  color: #81a2be;
}
.markup.inserted {
  color: #b5bd68;
}
.markup.quote {
  color: #de935f;
}
.markup.raw {
  color: #b5bd68;
}
.source.gfm .markup {
  -webkit-font-smoothing: auto;
}
.source.gfm .link .entity {
  color: #8abeb7;
}
.source.cs .keyword.operator {
  color: #b294bb;
}
.source.json .meta.structure.dictionary.json > .string.quoted.json {
  color: #cc6666;
}
.source.json .meta.structure.dictionary.json > .string.quoted.json > .punctuation.string {
  color: #cc6666;
}
.source.json .meta.structure.dictionary.json > .value.json > .string.quoted.json,
.source.json .meta.structure.array.json > .value.json > .string.quoted.json,
.source.json .meta.structure.dictionary.json > .value.json > .string.quoted.json > .punctuation,
.source.json .meta.structure.array.json > .value.json > .string.quoted.json > .punctuation {
  color: #b5bd68;
}
.source.json .meta.structure.dictionary.json > .constant.language.json,
.source.json .meta.structure.array.json > .constant.language.json {
  color: #8abeb7;
}
</style>
  </head>
  <body class='markdown-preview'><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta http-equiv="Content-Style-Type" content="text/css">
  <meta name="generator" content="pandoc">
  <meta name="author" content="&#x418;&#x432;&#x430;&#x43D;&#x43E;&#x432;&#x430; &#x415;&#x43B;&#x438;&#x437;&#x430;&#x432;&#x435;&#x442;&#x430;">
  <title>Принципы активного обучения</title>
  <style type="text/css">code{white-space: pre;}</style>
  
</head>
<body>
<div id="header">
<h1 class="title">Принципы активного обучения</h1>
<h2 class="author">Иванова Елизавета</h2>
</div>
<h2 id="&#x432;&#x432;&#x435;&#x434;&#x435;&#x43D;&#x438;&#x435;">Введение</h2>
<p>Большинство задач машинного обучения, которые мы встречаем, относятся к обучению с учителем или без учителя. Рассмотрим задачу обучения с учителем. В ней обучающему алгоритму подаются на вход некоторые <em>размеченные</em> тренировочные данные, то есть пары объекты-ответы <span class="math"><script type="math/tex">\{(x_i, y_i)\}_i \in X \times Y</script></span>. Затем по ним обучается <em>модель</em> — параметрическое семейство функций <span class="math"><script type="math/tex">g(x, \theta): X \times \Theta \to Y</script></span>, и под <em>обучаться</em> понимается нахождение оптимального <span class="math"><script type="math/tex">\theta</script></span>, аргминимума функции потерь. Такой подход, когда в обучении используются только исходные размеченные данные, относится к <em>пассивному обучению</em>.</p>
<p><em>Активное обучение</em> решает задачи обучения с учителем, используя дополнительно <em>неразмеченные</em> данные, то есть объекты, для которых неизвестен ответ (класс, метка, значение целевой функции на этом объекте).</p>
<p>Предположим, что в нашей конкретной задаче обучения с учителем есть некоторая функция, которая сопоставляет ответ любому объекту из неразмеченных данных, но при этом является дорогостоящей процедурой (достаточно дорогой, чтобы не обращаться к ней постоянно). Будем называть ее <em>оракулом</em>. Тогда основная идея активного обучения — выбирать объекты среди неразмеченных данных, которые помогут <em>быстрее обучить модель</em>, и тем самым минимизировать кол-во вызовов оракула.</p>
<center>
<p><img src="/home/ivanova/Documents/seminar2016/active_learning/img/al.png?v=1480851541656" width="640"></p>
<em><strong>Рис. 1: Схема активного обучения (семплирование из пула)</strong></em>
</center>
<p>Активное обучение применяется в любой области, где построение обучающей выборки затратная процедура. Если вы занимаетесь классификацией текстов, изображений и т.п., найти неразмеченные данные не составляет труда. Но готовые размеченные датасетами, которые подходят под вашу задачу, найти сложнее, приходится размечать самому, или просить друзей, или обращаться в специальные сервисы (Яндекс.Толока, Amazon Mechanical Turk). Друзей сильно мучить не хочется, а сервисам нужно платить, поэтому здесь пригодится активное обучение.</p>
<h4 id="&#x43F;&#x43E;&#x447;&#x435;&#x43C;&#x443;-&#x44D;&#x442;&#x43E;-&#x440;&#x430;&#x431;&#x43E;&#x442;&#x430;&#x435;&#x442;">Почему это работает?</h4>
<p>Прежде чем перейти к теоретическим аспектам, давайте рассмотрим два примера, демонстрирующих, почему имеет смысл выбирать объекты для разметки и построения обучающей выборки.</p>
<p><em><strong>Пример 1.</strong></em> Дана функция <span class="math"><script type="math/tex">g(x, \theta) = \mathbb{I}_{x > \theta}(x),\, x \in [0, 1],\, \theta \in [0, 1]</script></span>, и нужно оценить <span class="math"><script type="math/tex">\theta</script></span>, при условии, что мы можем вычислять <span class="math"><script type="math/tex">g(x, \theta)</script></span> в произвольных точках <span class="math"><script type="math/tex">x</script></span>, но процедура эта крайне дорогая, и кол-во вызовов хочется сделать как можно меньше.</p>
<p>Наивный подход — взять для разметки равномерную сетку <span class="math"><script type="math/tex">\{i/n\},\, i = 1,\ldots, n - 1</script></span>. Оценка по времени этого решения — <span class="math"><script type="math/tex">O(n)</script></span> измерений.</p>
<center>
<p><img src="/home/ivanova/Documents/seminar2016/active_learning/img/naive.png?v=1480851541657" width="400"></p>
<em><strong>Рис. 2: Задача линейного разделения. Наивный подход</strong></em>
</center>
<p>Но быстрее эта задача решается двоичными поиском, временная сложность которого <span class="math"><script type="math/tex">O(\log n)</script></span>.</p>
<center>
<p><img src="/home/ivanova/Documents/seminar2016/active_learning/img/bs.png?v=1480851541657" width="405"></p>
<p><em><strong>Рис. 3: Задача линейного разделения. Двоичный поиск</strong></em></p>
</center>
<em><strong>Пример 2.</strong></em> Теперь рассмотрим пример, где сравниваются результаты классификации с помощью логистической регрессии и ее комбинации с активным обучением.
<center>
<p><img src="/home/ivanova/Documents/seminar2016/active_learning/img/example.png?v=1480851541658" width="660"></p>
<p><em><strong>Рис. 4: Пример работы обычной логистической регрессии (b) и логистической регрессии с активным обучением (с)</strong></em></p>
</center>
<p>На подграфике (a) изображены 400 точек, относящихся к одной из двух меток, сгенерированных из двух различных двумерных гауссовских распределений с одинаковой дисперисией (по 200 из каждого распределения).</p>
<p>На подграфике (b) изображена разделящая прямая, построенная логистической регрессией по 30 точкам, выбранных н.о.р. из пула всех данных. Точность классификации 70%. На следующем графике изображена разделящая прямая, построенная логистической регрессией с активным обучением по 30 точкам, выбранных по степени неуверенности. Точность классификации 90%.</p>
<p>Это пример еще раз подтверждает, что для активного обучения нужно меньшее кол-во точек, чтобы обучится до приемлемой точности.</p>
<h2 id="&#x43F;&#x43E;&#x441;&#x442;&#x430;&#x43D;&#x43E;&#x432;&#x43A;&#x430;-&#x437;&#x430;&#x434;&#x430;&#x447;&#x438;-&#x430;&#x43A;&#x442;&#x438;&#x432;&#x43D;&#x43E;&#x433;&#x43E;-&#x43E;&#x431;&#x443;&#x447;&#x435;&#x43D;&#x438;&#x44F;">Постановка задачи активного обучения</h2>
<p>Обозначения: - <span class="math"><script type="math/tex">x_i</script></span> — объекты, <span class="math"><script type="math/tex">y_i</script></span> — ответы (метки); - <span class="math"><script type="math/tex">U = \{x_i\}_i</script></span> (от <em>unlabeled</em>) — неразмеченные данные; - <span class="math"><script type="math/tex">L = \{(x_i, y_i)\}_i</script></span> (от <em>labeled</em>) — размеченные тренировочные данные.</p>
<p><strong>Задача</strong>: обучить модель по размеченным данным <span class="math"><script type="math/tex">L_0</script></span>, имея возможность обращаться к оракулу, чтобы получать метки для неразмеченных данныx <span class="math"><script type="math/tex">U_0</script></span>.</p>
<p><strong>Вход</strong>: размеченные данные <span class="math"><script type="math/tex">L_0</script></span>, максимальное число вызовов оракула <span class="math"><script type="math/tex">K</script></span>, неразмеченные данные <span class="math"><script type="math/tex">U_0</script></span>.</p>
<p><strong>Алгоритм</strong>: Обучить модель на <span class="math"><script type="math/tex">L_0</script></span>. Для <span class="math"><script type="math/tex">k = 0, 1, \ldots, K - 1</script></span>: 1. выбрать <span class="math"><script type="math/tex">x_{k + 1} \in U_k</script></span>; 2. узнать для него <span class="math"><script type="math/tex">y_{k + 1}</script></span>; 3. получить оптимальное <span class="math"><script type="math/tex">\theta_k</script></span> на тренировочных данных <span class="math"><script type="math/tex">L_{k + 1} := L_{k} \cup \{(x_{k + 1}, y_{k + 1})\}</script></span>.</p>
<p>Таким образом, активное обучение — это итерационный алгоритм, на каждой итерации которого к текущим тренировочным данным <span class="math"><script type="math/tex">L_{k}</script></span> добавляется объект <span class="math"><script type="math/tex">x_j</script></span> с меткой <span class="math"><script type="math/tex">y_j</script></span>, вычисленной с помощью оракула.</p>
<p><em><strong>Замечание 1</strong></em>: Конечно, на каждой итерации можно (даже нужно, потому что обучение модели может быть недешевой операцией) запрашивать метки не для одного объекта <span class="math"><script type="math/tex">x_{k + 1}</script></span>, а для нескольких <span class="math"><script type="math/tex">\{x_{k + 1}^{(i)}\}_{i = 1}^{m}</script></span> и дообучать модель на <span class="math"><script type="math/tex">L_{k} \cup \{(x_{k + 1}^{(i)}, y_{k + 1}^{(i)})\}_{i = 1}^{m}</script></span>.</p>
<p><em><strong>Замечание 2</strong></em>: Как выбирать начальное множество <span class="math"><script type="math/tex">L_0</script></span>? Наивный способ — равномерно из неразмеченных данных, а можно использовать специфику решаемой задачи. Например, для задач классификации предварительно сделать кластеризацию и взять центры кластеров.</p>
<h2 id="&#x441;&#x442;&#x440;&#x430;&#x442;&#x435;&#x433;&#x438;&#x438;-&#x432;&#x44B;&#x431;&#x43E;&#x440;&#x430;-&#x43E;&#x431;&#x44A;&#x435;&#x43A;&#x442;&#x43E;&#x432;-&#x434;&#x43B;&#x44F;-&#x440;&#x430;&#x437;&#x43C;&#x435;&#x442;&#x43A;&#x438;">Стратегии выбора объектов для разметки</h2>
<p>В активном обучении выделяют три типа источников неразмеченных данных:</p>
<ul>
<li><p>Семплирование из пула (pool-based sampling) — есть некоторая коллекция неразмеченных данных, и из нее достаются объекты для запроса метки у оракула;</p></li>
<li><p>Семплирование из потока (stream-based selective sampling) — есть поток данных, в каждый момент времени доступен один объект, принимается решение, отобрать этот объект для разметки или нет;</p></li>
<li><p>Генерация запросов (query sampling) — обучающий алгоритм сам строит объекты для разметки.</p></li>
</ul>
<p>Семплирование из коллекции наиболее встречающееся, и все перечисленные стратегии относятся к этому типу семплирования.</p>
<p><em><strong>Замечание 3</strong></em>: Как упоминалось выше, основная идея активного обучения — выбирать <em>наиболее информативные</em> (с учетом модели) объекты для разметки, чтобы кол-во вызовов оракула было минимально. Все ниже перечисленные стратегии являются эвристиками, потому что понятие <em>“наиболее информативные”</em> нельзя полностью формализовать, результаты об оптимальности конкретной стратегии можно получить разве что в каком-то отдельном частном случае.</p>
<p>Далее будем считать, что мы находимся в условиях задачи классификации, но подобные варианты стратегий можно сформулировать и для задач регрессии.</p>
<p>Введем обозначение <span class="math"><script type="math/tex">\varphi_{\theta}(x)</script></span> для функционала-эвристики, оценивающего прирост качества модели при добавлении <span class="math"><script type="math/tex">x</script></span> к тренировочным данным, так что <span class="math"><script type="math/tex">x^* = \arg\max_{x \in U} \varphi_{\theta}(x)</script></span> — следующая точка для разметки;</p>
<h4 id="&#x441;&#x442;&#x440;&#x430;&#x442;&#x435;&#x433;&#x438;&#x44F;-1-&#x432;&#x44B;&#x431;&#x43E;&#x440;-&#x43F;&#x43E;-&#x441;&#x442;&#x435;&#x43F;&#x435;&#x43D;&#x438;-&#x43D;&#x435;&#x443;&#x432;&#x435;&#x440;&#x435;&#x43D;&#x43D;&#x43E;&#x441;&#x442;&#x438;-uncertainty-sampling">Стратегия 1: выбор по степени неуверенности (uncertainty sampling)</h4>
<p>Идея: давайте добавлять к тренировочным данным те объекты, в которых модель больше всего неуверена.</p>
<p>Пусть <span class="math"><script type="math/tex">P_{\theta}(y|x)</script></span> — апостериорная вероятность того, что <span class="math"><script type="math/tex">x</script></span> относится к классу <span class="math"><script type="math/tex">y</script></span>. В случае бинарной классификации с <span class="math"><script type="math/tex">y = 0, 1</script></span> функционал-эвристику можно выбрать так <span class="math"><script type="math/tex">\varphi_{\theta}(x) = -|P_{\theta}(y = 0|x) - 0.5|</script></span>. Другими словами, берем те <span class="math"><script type="math/tex">x</script></span>, которые модель <span class="math"><script type="math/tex">\theta</script></span> относит к классу <span class="math"><script type="math/tex">0</script></span> с вероятностью, наиболее близкой к <span class="math"><script type="math/tex">0.5</script></span> (то есть вероятность, что <span class="math"><script type="math/tex">x</script></span> в классе <span class="math"><script type="math/tex">1</script></span> тоже близка к <span class="math"><script type="math/tex">0.5</script></span>).</p>
<p>В случае, когда классов больше, чем два:</p>
<ol style="list-style-type: lower-alpha">
<li><p><span class="math"><script type="math/tex">\varphi_{\theta}(x) = 1 - P_{\theta}(y^*|x)</script></span>, где <span class="math"><script type="math/tex">y^* = y^*(x)</script></span> — наиболее вероятный класс для <span class="math"><script type="math/tex">x</script></span>. Максимизация этой величины по <span class="math"><script type="math/tex">x</script></span> эквивалента <span class="math"><script type="math/tex">\min_x\max_{y\in Y} P_{\theta}(y|x)</script></span>. Только здесь не учитываются вероятности <span class="math"><script type="math/tex">P_{\theta}(y|x)</script></span> на других метках, поэтому был предложен следующий подход.</p></li>
<li><p><span class="math"><script type="math/tex">\varphi_{\theta}(x) = P_{\theta}(y^*_2|x) - P_{\theta}(y^*_1|x)</script></span>, где <span class="math"><script type="math/tex">y^*_i = y^*_i(x)</script></span> — <span class="math"><script type="math/tex">i</script></span>-й вероятный класс для <span class="math"><script type="math/tex">x</script></span>. Здесь <em>минимизируется</em> зазор между двумя лучшими предсказаниями <span class="math"><script type="math/tex">y_1</script></span> и <span class="math"><script type="math/tex">y_2</script></span>. Но если меток очень много, лучше использовать следующий функционал:</p></li>
<li><p><span class="math"><script type="math/tex">\varphi_{\theta}(x) = - \sum_{y \in Y} P_{\theta}(y|x) \log P_{\theta}(y|x)</script></span> — не что иное, как энтропия. Вспомните, что ее максимум достигается на равномерном распределении.</p></li>
</ol>
<p>Ниже на тепловых картах сравниваются значения функционалов-эвристик a)-с) (обратите внимание, что тепловые шкалы на трех графиках разные). Объекты, относительно которых модель больше всего неуверена, находятся в центре, так как для них все апостериорные вероятности <span class="math"><script type="math/tex">P_{\theta}(y_i|x)</script></span> примерно равны. Объекты, находящиеся ближе к углам, считаются менее информативными, так как модель больше всего уверена в предсказанным для них меткам.</p>
<center>
<p><img src="/home/ivanova/Documents/seminar2016/active_learning/img/um.png?v=1480851541658" width="700"></p>
<em><strong>Рис. 5: Тепловые карты различных <span class="math"><script type="math/tex">\varphi_k(x)</script></span> в случае трех классов. Синяя область — наименее информативные объекты, красная область — наиболее информативные объекты согласно данной стратегии</strong></em>
</center>
<p>Форму области красного цвета на каждом графике легко объяснить — для a) она имеет форму треугольника, так как значение функционала определяется вероятностью <span class="math"><script type="math/tex">P_{\theta}(y^*|x)</script></span>, для b) область сосредоточена вдоль перпендикуляров от центра треугольника, так как она соответствует равенству <span class="math"><script type="math/tex">P_{\theta}(y^*_1|x)</script></span> и <span class="math"><script type="math/tex">P_{\theta}(y^*_2|x)</script></span>. Что касается c), то в этом функционале учитываются все априорные вероятности, и если для точки <span class="math"><script type="math/tex">x</script></span> вероятность <span class="math"><script type="math/tex">P_{\theta}(y|x)</script></span> мала для некоторого <span class="math"><script type="math/tex">y</script></span> (такие <span class="math"><script type="math/tex">x</script></span> располагаются вдоль сторон), то эта точка не включатся в число информативных по стратегии c) (так как модель считает, что этот объект не относится к тому классу).</p>
<h4 id="&#x441;&#x442;&#x440;&#x430;&#x442;&#x435;&#x433;&#x438;&#x44F;-2-&#x43E;&#x442;&#x431;&#x43E;&#x440;-&#x43A;&#x43E;&#x43C;&#x438;&#x442;&#x435;&#x442;&#x43E;&#x43C;-query-by-committee">Стратегия 2: отбор комитетом (query by committee)</h4>
<p><em>Комитетом моделей</em> будем называть набор моделей, обученных на одном и том же множестве <span class="math"><script type="math/tex">L</script></span>. Обозначение — <span class="math"><script type="math/tex">C_L = \{\theta_1,\ldots,\theta_m\}</script></span>. Идея стратегии: выбирать объекты с наибольшей <em>несогласованностью</em> комитетов моделей.</p>
<p>Пусть</p>
<ul>
<li><p><span class="math"><script type="math/tex">V(y, x) = |{\theta \in C_{L}: y_{\theta}(x) = y}|</script></span> — количество моделей из комитета <span class="math"><script type="math/tex">C_{L}</script></span>, выбравших <span class="math"><script type="math/tex">y</script></span>;</p></li>
<li><p><span class="math"><script type="math/tex">\hat{P}(y|x) = V(y, x) / |C_{L}|</script></span> — соответственно доля моделей, выбравших <span class="math"><script type="math/tex">y</script></span>.</p></li>
</ul>
<p>Тогда несогласованность можно определить через <span class="math"><script type="math/tex">\varphi_{\theta}(x) = - \sum_{y \in Y} \hat{P}(y|x) \log \hat{P}(y|x)</script></span> — энтропию голосующей вероятности.</p>
<p>Как уже говорилось, максимум энтропии достигается на равномерном распределении, значит, максимизация этого функционала соответсвует выбору объекта, для которого <span class="math"><script type="math/tex">V(y, x)</script></span> примерно равны для каждого <span class="math"><script type="math/tex">y</script></span>.</p>
<h4 id="&#x441;&#x442;&#x440;&#x430;&#x442;&#x435;&#x433;&#x438;&#x44F;-3-&#x441;&#x43E;&#x43A;&#x440;&#x430;&#x449;&#x435;&#x43D;&#x438;&#x435;-&#x43F;&#x440;&#x43E;&#x441;&#x442;&#x440;&#x430;&#x43D;&#x441;&#x442;&#x432;&#x430;-&#x440;&#x435;&#x448;&#x435;&#x43D;&#x438;&#x439;-version-space-reduction">Стратегия 3: Сокращение пространства решений (version space reduction)</h4>
<p>Идея этого подхода заключается в уменьшении пространствами решений (version space). Под пространством решений в общем случае понимают множество гипотез, которые согласуются с текущими тренировочными данными. Понятие получается довольно размытое, но в задаче классификации гипотезы <em>связаны</em> с всевозможными разделяющими гиперплоскостями и т.п.</p>
<center>
<p><img src="/home/ivanova/Documents/seminar2016/active_learning/img/vs.png?v=1480851541658" width="660"></p>
<p><em><strong>Рис. 6: Примеры пространств решений</strong></em></p>
</center>
<p>Поскольку пространство решений это очень широкое понятие, то стратегии его уменьшения можно описать только на примере конкретной задачи. Ниже приведен пример, как комбинируется SVM и активное обучение, и уменьшение пространства решений его ключевая идея.</p>
<p>Стоит отметить, что отбор комитетом на самом деле тоже уменьшает пространство решений.</p>
<h4 id="&#x441;&#x442;&#x440;&#x430;&#x442;&#x435;&#x433;&#x438;&#x44F;-4-&#x43E;&#x436;&#x438;&#x434;&#x430;&#x435;&#x43C;&#x43E;&#x435;-&#x432;&#x43B;&#x438;&#x44F;&#x43D;&#x438;&#x435;-&#x43D;&#x430;-&#x43C;&#x43E;&#x434;&#x435;&#x43B;&#x44C;-expected-model-change">Стратегия 4: ожидаемое влияние на модель (expected model change)</h4>
<p>Идея: будем искать такой объект, добавление которого в обучающее множество приведет к наибольшему <em>изменению</em> параметра модели <span class="math"><script type="math/tex">\theta</script></span>. Само изменение будем мерять с помощью нормы градиента функционала обучения <span class="math"><script type="math/tex">\ell_{\theta}(L)</script></span>, где <span class="math"><script type="math/tex">L</script></span> — обучающее множество.</p>
<p>Нам нужно посчитать влияние на модель, но мы не знаем метку на <span class="math"><script type="math/tex">x</script></span> из неразмеченного множества <span class="math"><script type="math/tex">U</script></span>. Однако у нас есть апостриорное распределение <span class="math"><script type="math/tex">P_{\theta}(y|x)</script></span>, поэтому будем считать взвешенную сумму <span class="math"><script type="math/tex">\varphi_{\theta}(x) = \sum_{y \in Y} P_{\theta}(y|x) \cdot \| \nabla\ell_{\theta}(L \cup \{(x, y)\})\|</script></span>, другими словами, мат. ожидание нормы градиента.</p>
<p>Вспомните, что <span class="math"><script type="math/tex">\nabla\ell_{\theta}(L) = 0</script></span> (<span class="math"><script type="math/tex">\theta</script></span> оптимум на обучающем множестве <span class="math"><script type="math/tex">L</script></span>), поэтому можно воспользоваться следующим приближением <span class="math"><script type="math/tex">\nabla\ell_{\theta}(L \cup \{(x, y)\}) \approx \nabla\ell_{\theta}(\{(x, y)\})</script></span> для оптимизации вычислений.</p>
<h4 id="&#x441;&#x442;&#x440;&#x430;&#x442;&#x435;&#x433;&#x438;&#x44F;-5-&#x43E;&#x436;&#x438;&#x434;&#x430;&#x435;&#x43C;&#x43E;&#x435;-&#x443;&#x43C;&#x435;&#x43D;&#x44C;&#x448;&#x435;&#x43D;&#x438;&#x435;-&#x43E;&#x448;&#x438;&#x431;&#x43A;&#x438;-expected-error-reduction">Стратегия 5: ожидаемое уменьшение ошибки (expected error reduction)</h4>
<p>Идея: максимизация уверенности на остальных объектах в неразмеченном множестве.</p>
<p>Пусть <span class="math"><script type="math/tex">\theta_+(x, y)</script></span> — оптимальный вектор параметров после дообучения модели на <span class="math"><script type="math/tex">L \cup \{(x, y)\}</script></span>, а <span class="math"><script type="math/tex">y^* = y^*(z)</script></span> — наиболее вероятный класс для <span class="math"><script type="math/tex">z</script></span> в модели, обученной на <span class="math"><script type="math/tex">L</script></span>.</p>
<p>Рассмотрим функционал <span class="math"><script type="math/tex">\varphi_{\theta}(x) = - \sum_{y \in Y} P_{\theta}(y|x) \sum_{z \in U} (1 - P_{\theta_+(x, y)}(y^*|z))</script></span>, его максимизация соответствует минимизации <span class="math"><script type="math/tex">\sum_{y \in Y} P_{\theta}(y|x) \sum_{z \in U} (1 - P_{\theta_+(x, y)}(y^*|z))</script></span>. То есть находим <span class="math"><script type="math/tex">x</script></span>, добавление которого увеличивает <span class="math"><script type="math/tex">P_{\theta_+(x, y)}(y^*|z))</script></span> (делает как можно ближе к <span class="math"><script type="math/tex">1</script></span>) для всех неразмеченных <span class="math"><script type="math/tex">z</script></span>. Так как метку для <span class="math"><script type="math/tex">x</script></span> мы не знаем, то делаем усреднение по всем <span class="math"><script type="math/tex">y</script></span>.</p>
<p><em><strong>Замечание</strong></em>: В стратегиях выбор по степени неуверенности, отбор комитетом, ожидаемое влияние на модель к числу информативных объектов могут попасть аутлаеры. Поэтому их нужно исключить заранее, или рассмотривать не <span class="math"><script type="math/tex">\max_{x \in U} \varphi_{\theta}(x)</script></span>, а <span class="math"><script type="math/tex">\max_{x \in U} \varphi_{\theta}(x)\cdot \big(\frac{1}{|U|}\sum_{z \in U}\rho(x, z)\big)^{\beta}</script></span>, где <span class="math"><script type="math/tex">\rho</script></span> — это некоторая мера близости объектов, <span class="math"><script type="math/tex">\beta</script></span> — нормировочный коэффициент, чтобы контролировать величину весов. Последняя стратегия устойчива к выбросам.</p>
<h2 id="&#x430;&#x43A;&#x442;&#x438;&#x432;&#x43D;&#x43E;&#x435;-&#x43E;&#x431;&#x443;&#x447;&#x435;&#x43D;&#x438;&#x435;-&#x432;-svm">Активное обучение в SVM</h2>
<p>Посмотрим, как активное обучение комбинируется с классическими методами классификации, таким как SVM. Описанный ниже метод относится к статье <span class="citation">(Tong and Koller 2001)</span>, краткий обзор других статей на эту тему можно найти в <span class="citation">(Settles 2010)</span>.</p>
<p>Будем предполать, что:</p>
<ul>
<li><p>данные линейно разделимы (но подход можно адаптировать под допущение ограниченного кол-ва ошибок, применять kernel trick, как это сделано в SVM);</p></li>
<li><p>класса два, их метки <span class="math"><script type="math/tex">1</script></span> и <span class="math"><script type="math/tex">-1</script></span>.</p></li>
</ul>
<h4 id="&#x43D;&#x430;&#x43F;&#x43E;&#x43C;&#x438;&#x43D;&#x430;&#x43D;&#x438;&#x435;">Напоминание</h4>
<p>В обычном SVM ищется классификатор вида <span class="math"><script type="math/tex">f(x) = {\rm sign}(\langle x, w \rangle - w_0)</script></span> и решается оптимизационная задача <span class="math"><script type="math/tex">\|w\|^2/2 \to \min_{w, w_0}</script></span> при условиях <span class="math"><script type="math/tex">y_i(\langle x_i, w \rangle - w_0) \geq 1</script></span>, где <span class="math"><script type="math/tex">w, w_0</script></span> — параметры алгоритма.</p>
<p>Величина <span class="math"><script type="math/tex">|\langle x_i, w \rangle - w_0|/\|w\|</script></span> — это расстояние от точки <span class="math"><script type="math/tex">x_i</script></span> до разделяющей гиперплоскости <span class="math"><script type="math/tex">\langle x, w \rangle - w_0 = 0</script></span>, поэтому когда минимизируется <span class="math"><script type="math/tex">\|w\|</script></span>, максимизируется зазор между <em>опорными</em> гиперплоскостями, которые проходят через ближайшие к разделяющей гиперплоскости <span class="math"><script type="math/tex">x_i</script></span>. Можно считать, что <span class="math"><script type="math/tex">\|w\| = 1</script></span>, тогда оптимизационную задачу можно переписать как <span class="math"><script type="math/tex">\min_i y_i (\langle x_i, w \rangle - w_0) \to \max_{w, w_0}</script></span> при условиях <span class="math"><script type="math/tex">\|w\| = 1</script></span> и <span class="math"><script type="math/tex">y_i(\langle x_i, w \rangle - w_0) \geq 1</script></span>.</p>
<h4 id="&#x43E;-&#x43F;&#x440;&#x43E;&#x441;&#x442;&#x440;&#x430;&#x43D;&#x441;&#x442;&#x432;&#x435;-&#x440;&#x435;&#x448;&#x435;&#x43D;&#x438;&#x439;">О пространстве решений</h4>
<p>По определению пространством решений будет являться <span class="math"><script type="math/tex">\mathcal{V} = \{f |\, y_if(x_i) > 0,\, i = 1 \ldots n\}</script></span>. Поскольку между <span class="math"><script type="math/tex">f</script></span> и <span class="math"><script type="math/tex">w</script></span> существует биекция, то можно считать, что <span class="math"><script type="math/tex">\mathcal{V} = \{w\,|\, \|w\| = 1,\, y_i (\langle x_i, w \rangle - w_0) > 0,\, i = 1\ldots n \}</script></span>.</p>
<p>Обозначим за <span class="math"><script type="math/tex">Area(\mathcal{V})</script></span> площадь пространства решений.</p>
<h4 id="&#x442;&#x435;&#x43E;&#x440;&#x435;&#x442;&#x438;&#x447;&#x435;&#x441;&#x43A;&#x43E;&#x435;-&#x43E;&#x442;&#x441;&#x442;&#x443;&#x43F;&#x43B;&#x435;&#x43D;&#x438;&#x435;-&#x440;&#x435;&#x437;&#x443;&#x43B;&#x44C;&#x442;&#x430;&#x442;-&#x43A;&#x43E;&#x442;&#x43E;&#x440;&#x43E;&#x433;&#x43E;-&#x438;&#x441;&#x43F;&#x43E;&#x43B;&#x44C;&#x437;&#x443;&#x435;&#x442;&#x441;&#x44F;-&#x434;&#x430;&#x43B;&#x44C;&#x448;&#x435;">Теоретическое отступление, результат которого используется дальше</h4>
<p>Если предположить, что <span class="math"><script type="math/tex">\|x_i\| = 1</script></span>, то <span class="math"><script type="math/tex">\min_i y_i(\langle x_i, w \rangle - w_0) = \min_i |\langle w, y_i x_i\rangle - y_i w_0| = \min_i |\langle w, y_i x_i\rangle - y_i w_0|/\|y_ix_i\|</script></span>, а значит зазор между гиперплоскостями также равен минимальному расстоянию от <span class="math"><script type="math/tex">w</script></span> до гиперплоскости <span class="math"><script type="math/tex">\langle v, y_i x_i\rangle - y_i w_0 = 0</script></span> относительно <span class="math"><script type="math/tex">v</script></span>.</p>
<p>Отсюда следует, что оптимальный параметр <span class="math"><script type="math/tex">w</script></span> — это центр гиперсферы наибольшего радиуса в <span class="math"><script type="math/tex">\mathcal{V}</script></span>, которая бы не пересекалась ни с одной из гиперплоскостей полном пространстве.</p>
<center>
<p><img src="/home/ivanova/Documents/seminar2016/active_learning/img/svm+al.png?v=1480851541658" width="550"></p>
<p><em><strong>Рис. 7: Активное обучение в SVM</strong></em></p>
</center>
<h4 id="&#x43E;&#x431;-&#x430;&#x43A;&#x442;&#x438;&#x432;&#x43D;&#x43E;&#x43C;-&#x43E;&#x431;&#x443;&#x447;&#x435;&#x43D;&#x438;&#x438;">Об активном обучении</h4>
<p>Пусть также <span class="math"><script type="math/tex">\mathcal{V}_k^- = \mathcal{V}_k \cap \{w\,|\, \langle w, x\rangle < 0\}</script></span> и <span class="math"><script type="math/tex">\mathcal{V}_k^+ = \mathcal{V}_k \cap \{w\,|\, \langle w, x\rangle > 0\}</script></span>, где <span class="math"><script type="math/tex">\mathcal{V}_k</script></span> — это пространство решений после <span class="math"><script type="math/tex">k</script></span> итераций активного обучения. Другими словами, <span class="math"><script type="math/tex">\mathcal{V}_k^-</script></span> и <span class="math"><script type="math/tex">\mathcal{V}_k^+</script></span> — это пространства решений, если метка для <span class="math"><script type="math/tex">x</script></span> оказалась <span class="math"><script type="math/tex">-1</script></span> и <span class="math"><script type="math/tex">1</script></span> соответсвенно. Также за <span class="math"><script type="math/tex">\mathcal{V}_k(\ell)</script></span> обозначим пространство решений после <span class="math"><script type="math/tex">k</script></span> итераций активного обучения, который использует стратегию <span class="math"><script type="math/tex">\ell</script></span>.</p>
<p>В <span class="citation">(Tong and Koller 2001)</span> приводится лемма, говорящая о том, что оптимальной стратегий будет деление <span class="math"><script type="math/tex">Area(\mathcal{V})</script></span> примерно пополам. Точнее, если выбрать такую стратегию в активном обучении, которую условно обозначим за <span class="math"><script type="math/tex">\ell^*</script></span>, то для любой другой стратегии <span class="math"><script type="math/tex">\ell</script></span> выполняется неравенство: <span class="math"><script type="math/tex; mode=display">\sup_{P \in \mathcal{P}} {\rm E}_P[Area(\mathcal{V}_i(\ell^*))] \leq \sup_{P \in \mathcal{P}} {\rm E}_P[Area(\mathcal{V}_i(\ell^*))]</script></span> для любого <span class="math"><script type="math/tex">i \geq 1</script></span>, где <span class="math"><script type="math/tex">\mathcal{P}</script></span> — множество всех условных распределений <span class="math"><script type="math/tex">P(y|x)</script></span>. При этом строгое неравенство достигается, если существует итерация <span class="math"><script type="math/tex">j \in 1,\ldots, i</script></span>, такая, что <span class="math"><script type="math/tex">\ell</script></span> не делит пространство решений <span class="math"><script type="math/tex">\mathcal{V}_{j - 1}</script></span> пополам.</p>
<p>Пусть <span class="math"><script type="math/tex">w_k</script></span> — центр гиперсферы наибольшего радиуса, которая вписана в пространство решений <span class="math"><script type="math/tex">\mathcal{V}_k</script></span>. Предлагается три способа делить пространство решений так, чтобы площади полученных областей были примерно равны:</p>
<ul>
<li><em>Simple Margin</em>. Теперь перебирая все неразмеченные объекты <span class="math"><script type="math/tex">x</script></span>, выберем тот, для которого соответсвующая гиперплоскость ближе всего к центру <span class="math"><script type="math/tex">w_k</script></span>. По отступлению выше такой <span class="math"><script type="math/tex">x_k</script></span> находится ближе всего к разделяющей гиперплоскости в пространстве объектов.</li>
</ul>
<center>
<p><img src="/home/ivanova/Documents/seminar2016/active_learning/img/simplemargin.png?v=1480851541658" width="550"></p>
<p><em><strong>Рис. 8: Simple Margin. (a) выбирается ближайшая гиперплоскость b. (b) выбирается ближайшая гиперплоскость a</strong></em></p>
</center>
<p>Обозначим за <span class="math"><script type="math/tex">m_k</script></span> радиус гиперсферы. Рассмотрим неразмеченный объект <span class="math"><script type="math/tex">x</script></span>, <span class="math"><script type="math/tex">\mathcal{V}_k^-</script></span>, <span class="math"><script type="math/tex">\mathcal{V}_k^+</script></span> — подпространства в пространсве решений, соответствующие отрицательной и положительной метке <span class="math"><script type="math/tex">x</script></span>. Теперь обозначим за <span class="math"><script type="math/tex">m^-_k</script></span> и <span class="math"><script type="math/tex">m^+_k</script></span> радиусы вписанных в <span class="math"><script type="math/tex">\mathcal{V}_k^-</script></span> и <span class="math"><script type="math/tex">\mathcal{V}_k^+</script></span> сфер.</p>
<ul>
<li><p><em>MaxMin Margin</em>. Эта стратегия предлагает искать <span class="math"><script type="math/tex">\arg\max_x \min\{m^+_k, m^-_k\}</script></span>. Так как <span class="math"><script type="math/tex">m_k</script></span> cвязан с <span class="math"><script type="math/tex">Area(\mathcal{V}_k)</script></span>, то на самом деле максимизируется <span class="math"><script type="math/tex">\min\{Area(\mathcal{V}_k^+), Area(\mathcal{V}^-_k)\}</script></span>, тогда <span class="math"><script type="math/tex">Area(\mathcal{V}_k^+)</script></span> и <span class="math"><script type="math/tex">Area(\mathcal{V}^-_k)</script></span> будут максимально близки.</p></li>
<li><p><em>Ratio Margin</em>. В этой стратегии ищется <span class="math"><script type="math/tex">\arg\max_x \min\{m^+/m^-, m^-/m^+\}</script></span>, она объясняется так же, как и стратегия MaxMin Margin.</p></li>
</ul>
<center>
<p><img src="/home/ivanova/Documents/seminar2016/active_learning/img/maxminmargin.png?v=1480851541658" width="550"></p>
<p><em><strong>Рис. 9: (a) MaxMin Margin — выбирается гиперплоскость b. (b) Ratio Margin — выбирается гиперплоскость e</strong></em></p>
</center>
<h2 id="&#x43D;&#x435;&#x434;&#x43E;&#x441;&#x442;&#x430;&#x442;&#x43A;&#x438;-&#x430;&#x43A;&#x442;&#x438;&#x432;&#x43D;&#x43E;&#x433;&#x43E;-&#x43E;&#x431;&#x443;&#x447;&#x435;&#x43D;&#x438;&#x44F;">Недостатки активного обучения</h2>
<p>Стратегии активного обучения устроены так, что они рекомендуют точки, лежащие, например, вблизи разделяющей гиперплоскости в текущей модели. Это хорошо работает, если нет крупных областей, где модель бы ошибалась. Таким образом, у алгоритма среди данных есть необследованные участки, что повышается ошибку на тестовых данных.</p>
<p>Возникает так называемая exploration-exploitation dilemma, но есть приемы, связанные с применением контекстных бандитов <span class="citation">(см. Bouneffouf and others 2014)</span> и случайным изучением всего неразмеченного множества <span class="citation">(см. Bouneffouf 2015)</span>, которые не увеличивают время обучения так, что сама идея активного обучения теряет смысл.</p>
<h2 id="&#x43B;&#x438;&#x442;&#x435;&#x440;&#x430;&#x442;&#x443;&#x440;&#x430;" class="unnumbered">Литература</h2>
<div id="refs" class="references">
<div id="ref-Bouneffouf2">
<p>Bouneffouf, Djallel. 2015. “Exponentiated Gradient Exploration for Active Learning.”</p>
</div>
<div id="ref-Bouneffouf1">
<p>Bouneffouf, Djallel, and others. 2014. “Contextual Bandit for Active Learning: Active Thompson Sampling.”</p>
</div>
<div id="ref-DDBAL">
<p>Jiang, Jun, and Horace Ip. 2007. “Dynamic Distance-Based Active Learning with SVM.” <em>Machine Learning and Data Mining in Pattern Recognition. Lecture Notes in Artificial Intelligence</em>. Springer-Verlag Berlin Heidelberg.</p>
</div>
<div id="ref-Settles">
<p>Settles, Burr. 2010. “Active Learning Literature Survey.” Computer Sciences Technical Report 1648. University of Wisconsin–Madison.</p>
</div>
<div id="ref-TongKoller">
<p>Tong, Simon, and Daphne Koller. 2001. “Support Vector Machine Active Learning with Applications to Text Classification.” <em>Journal of Machine Learning Research</em>, 45–66.</p>
</div>
</div>
</body>
</html></body>
</html>
