\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Принципы активного обучения},
            pdfauthor={Иванова Елизавета},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\title{Принципы активного обучения}
\author{Иванова Елизавета}
\date{}

\begin{document}
\maketitle

\subsection{Введение}\label{ux432ux432ux435ux434ux435ux43dux438ux435}

Большинство задач машинного обучения, которые мы встречаем, относятся к
обучению с учителем или без учителя. Рассмотрим задачу обучения с
учителем. В ней обучающему алгоритму подаются на вход некоторые
\emph{размеченные} тренировочные данные, то есть пары объекты-ответы
\(\{(x_i, y_i)\}_i \in X \times Y\). Затем по ним обучается
\emph{модель} --- параметрическое семейство функций
\(g(x, \theta): X \times \Theta \to Y\), и под \emph{обучаться}
понимается нахождение оптимального \(\theta\), аргминимума функции
потерь. Такой подход, когда в обучении используются только исходные
размеченные данные, относится к \emph{пассивному обучению}.

\emph{Активное обучение} решает задачи обучения с учителем, используя
дополнительно \emph{неразмеченные} данные, то есть объекты, для которых
неизвестен ответ (класс, метка, значение целевой функции на этом
объекте).

Предположим, что в нашей конкретной задаче обучения с учителем есть
некоторая функция, которая сопоставляет ответ любому объекту из
неразмеченных данных, но при этом является дорогостоящей процедурой
(достаточно дорогой, чтобы не обращаться к ней постоянно). Будем
называть ее \emph{оракулом}. Тогда основная идея активного обучения ---
выбирать объекты среди неразмеченных данных, которые помогут
\emph{быстрее обучить модель}, и тем самым минимизировать кол-во вызовов
оракула.

\begin{figure}[htbp]
\centering
\includegraphics[width=6.66667in]{img/al.png}
\caption{Рис. 1: Схема активного обучения (семплирование из пула)}
\end{figure}

Активное обучение применяется в любой области, где построение обучающей
выборки затратная процедура. Если вы занимаетесь классификацией текстов,
изображений и т.п., найти неразмеченные данные не составляет труда. Но
готовые размеченные датасетами, которые подходят под вашу задачу, найти
сложнее, приходится размечать самому, или просить друзей, или обращаться
в специальные сервисы (Яндекс.Толока, Amazon Mechanical Turk). Друзей
сильно мучить не хочется, а сервисам нужно платить, поэтому здесь
пригодится активное обучение.

\paragraph{Почему это
работает?}\label{ux43fux43eux447ux435ux43cux443-ux44dux442ux43e-ux440ux430ux431ux43eux442ux430ux435ux442}

Прежде чем перейти к теоретическим аспектам, давайте рассмотрим два
примера, демонстрирующих, почему имеет смысл выбирать объекты для
разметки и построения обучающей выборки.

\emph{\textbf{Пример 1.}} Дана функция
\(g(x, \theta) = \mathbb{I}_{x > \theta}(x),\, x \in [0, 1],\, \theta \in [0, 1]\),
и нужно оценить \(\theta\), при условии, что мы можем вычислять
\(g(x, \theta)\) в произвольных точках \(x\), но процедура эта крайне
дорогая, и кол-во вызовов хочется сделать как можно меньше.

Наивный подход --- взять для разметки равномерную сетку
\(\{i/n\},\, i = 1,\ldots, n - 1\). Оценка по времени этого решения ---
\(O(n)\) измерений.

\begin{figure}[htbp]
\centering
\includegraphics[width=4.16667in]{img/naive.png}
\caption{Рис. 2: Задача линейного разделения. Наивный подход}
\end{figure}

Но быстрее эта задача решается двоичными поиском, временная сложность
которого \(O(\log n)\).

\begin{figure}[htbp]
\centering
\includegraphics[width=4.21875in]{img/bs.png}
\caption{Рис. 3: Задача линейного разделения. Двоичный поиск}
\end{figure}

\emph{\textbf{Пример 2.}} Теперь рассмотрим пример, где сравниваются
результаты классификации с помощью логистической регрессии и ее
комбинации с активным обучением.

\begin{figure}[htbp]
\centering
\includegraphics[width=6.87500in]{img/example.png}
\caption{Рис. 4: Пример работы обычной логистической регрессии (b) и
логистической регрессии с активным обучением (с)}
\end{figure}

На подграфике (a) изображены 400 точек, относящихся к одной из двух
меток, сгенерированных из двух различных двумерных гауссовских
распределений с одинаковой дисперисией (по 200 из каждого
распределения).

На подграфике (b) изображена разделящая прямая, построенная
логистической регрессией по 30 точкам, выбранных н.о.р. из пула всех
данных. Точность классификации 70\%. На следующем графике изображена
разделящая прямая, построенная логистической регрессией с активным
обучением по 30 точкам, выбранных по степени неуверенности. Точность
классификации 90\%.

Это пример еще раз подтверждает, что для активного обучения нужно
меньшее кол-во точек, чтобы обучится до приемлемой точности.

\subsection{Постановка задачи активного
обучения}\label{ux43fux43eux441ux442ux430ux43dux43eux432ux43aux430-ux437ux430ux434ux430ux447ux438-ux430ux43aux442ux438ux432ux43dux43eux433ux43e-ux43eux431ux443ux447ux435ux43dux438ux44f}

Обозначения: - \(x_i\) --- объекты, \(y_i\) --- ответы (метки); -
\(U = \{x_i\}_i\) (от \emph{unlabeled}) --- неразмеченные данные; -
\(L = \{(x_i, y_i)\}_i\) (от \emph{labeled}) --- размеченные
тренировочные данные.

\textbf{Задача}: обучить модель по размеченным данным \(L_0\), имея
возможность обращаться к оракулу, чтобы получать метки для неразмеченных
данныx \(U_0\).

\textbf{Вход}: размеченные данные \(L_0\), максимальное число вызовов
оракула \(K\), неразмеченные данные \(U_0\).

\textbf{Алгоритм}: Обучить модель на \(L_0\). Для
\(k = 0, 1, \ldots, K - 1\): 1. выбрать \(x_{k + 1} \in U_k\); 2. узнать
для него \(y_{k + 1}\); 3. получить оптимальное \(\theta_k\) на
тренировочных данных
\(L_{k + 1} := L_{k} \cup \{(x_{k + 1}, y_{k + 1})\}\).

Таким образом, активное обучение --- это итерационный алгоритм, на
каждой итерации которого к текущим тренировочным данным \(L_{k}\)
добавляется объект \(x_j\) с меткой \(y_j\), вычисленной с помощью
оракула.

\emph{\textbf{Замечание 1}}: Конечно, на каждой итерации можно (даже
нужно, потому что обучение модели может быть недешевой операцией)
запрашивать метки не для одного объекта \(x_{k + 1}\), а для нескольких
\(\{x_{k + 1}^{(i)}\}_{i = 1}^{m}\) и дообучать модель на
\(L_{k} \cup \{(x_{k + 1}^{(i)}, y_{k + 1}^{(i)})\}_{i = 1}^{m}\).

\emph{\textbf{Замечание 2}}: Как выбирать начальное множество \(L_0\)?
Наивный способ --- равномерно из неразмеченных данных, а можно
использовать специфику решаемой задачи. Например, для задач
классификации предварительно сделать кластеризацию и взять центры
кластеров.

\subsection{Стратегии выбора объектов для
разметки}\label{ux441ux442ux440ux430ux442ux435ux433ux438ux438-ux432ux44bux431ux43eux440ux430-ux43eux431ux44aux435ux43aux442ux43eux432-ux434ux43bux44f-ux440ux430ux437ux43cux435ux442ux43aux438}

В активном обучении выделяют три типа источников неразмеченных данных:

\begin{itemize}
\item
  Семплирование из пула (pool-based sampling) --- есть некоторая
  коллекция неразмеченных данных, и из нее достаются объекты для запроса
  метки у оракула;
\item
  Семплирование из потока (stream-based selective sampling) --- есть
  поток данных, в каждый момент времени доступен один объект,
  принимается решение, отобрать этот объект для разметки или нет;
\item
  Генерация запросов (query sampling) --- обучающий алгоритм сам строит
  объекты для разметки.
\end{itemize}

Семплирование из коллекции наиболее встречающееся, и все перечисленные
стратегии относятся к этому типу семплирования.

\emph{\textbf{Замечание 3}}: Как упоминалось выше, основная идея
активного обучения --- выбирать \emph{наиболее информативные} (с учетом
модели) объекты для разметки, чтобы кол-во вызовов оракула было
минимально. Все ниже перечисленные стратегии являются эвристиками,
потому что понятие \emph{``наиболее информативные''} нельзя полностью
формализовать, результаты об оптимальности конкретной стратегии можно
получить разве что в каком-то отдельном частном случае.

Далее будем считать, что мы находимся в условиях задачи классификации,
но подобные варианты стратегий можно сформулировать и для задач
регрессии.

Введем обозначение \(\varphi_{\theta}(x)\) для функционала-эвристики,
оценивающего прирост качества модели при добавлении \(x\) к
тренировочным данным, так что
\(x^* = \arg\max_{x \in U} \varphi_{\theta}(x)\) --- следующая точка для
разметки;

\paragraph{Стратегия 1: выбор по степени неуверенности (uncertainty
sampling)}\label{ux441ux442ux440ux430ux442ux435ux433ux438ux44f-1-ux432ux44bux431ux43eux440-ux43fux43e-ux441ux442ux435ux43fux435ux43dux438-ux43dux435ux443ux432ux435ux440ux435ux43dux43dux43eux441ux442ux438-uncertainty-sampling}

Идея: давайте добавлять к тренировочным данным те объекты, в которых
модель больше всего неуверена.

Пусть \(P_{\theta}(y|x)\) --- апостериорная вероятность того, что \(x\)
относится к классу \(y\). В случае бинарной классификации с \(y = 0, 1\)
функционал-эвристику можно выбрать так
\(\varphi_{\theta}(x) = -|P_{\theta}(y = 0|x) - 0.5|\). Другими словами,
берем те \(x\), которые модель \(\theta\) относит к классу \(0\) с
вероятностью, наиболее близкой к \(0.5\) (то есть вероятность, что \(x\)
в классе \(1\) тоже близка к \(0.5\)).

В случае, когда классов больше, чем два:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  \(\varphi_{\theta}(x) = 1 - P_{\theta}(y^*|x)\), где \(y^* = y^*(x)\)
  --- наиболее вероятный класс для \(x\). Максимизация этой величины по
  \(x\) эквивалента \(\min_x\max_{y\in Y} P_{\theta}(y|x)\). Только
  здесь не учитываются вероятности \(P_{\theta}(y|x)\) на других метках,
  поэтому был предложен следующий подход.
\item
  \(\varphi_{\theta}(x) = P_{\theta}(y^*_2|x) - P_{\theta}(y^*_1|x)\),
  где \(y^*_i = y^*_i(x)\) --- \(i\)-й вероятный класс для \(x\). Здесь
  \emph{минимизируется} зазор между двумя лучшими предсказаниями \(y_1\)
  и \(y_2\). Но если меток очень много, лучше использовать следующий
  функционал:
\item
  \(\varphi_{\theta}(x) = - \sum_{y \in Y} P_{\theta}(y|x) \log P_{\theta}(y|x)\)
  --- не что иное, как энтропия. Вспомните, что ее максимум достигается
  на равномерном распределении.
\end{enumerate}

Ниже на тепловых картах сравниваются значения функционалов-эвристик
a)-с) (обратите внимание, что тепловые шкалы на трех графиках разные).
Объекты, относительно которых модель больше всего неуверена, находятся в
центре, так как для них все апостериорные вероятности
\(P_{\theta}(y_i|x)\) примерно равны. Объекты, находящиеся ближе к
углам, считаются менее информативными, так как модель больше всего
уверена в предсказанным для них меткам.

\begin{figure}[htbp]
\centering
\includegraphics[width=7.29167in]{img/um.png}
\caption{Рис. 5: Тепловые карты различных \(\varphi_k(x)\) в случае трех
классов. Синяя область --- наименее информативные объекты, красная
область --- наиболее информативные объекты согласно данной стратегии}
\end{figure}

Форму области красного цвета на каждом графике легко объяснить --- для
a) она имеет форму треугольника, так как значение функционала
определяется вероятностью \(P_{\theta}(y^*|x)\), для b) область
сосредоточена вдоль перпендикуляров от центра треугольника, так как она
соответствует равенству \(P_{\theta}(y^*_1|x)\) и
\(P_{\theta}(y^*_2|x)\). Что касается c), то в этом функционале
учитываются все априорные вероятности, и если для точки \(x\)
вероятность \(P_{\theta}(y|x)\) мала для некоторого \(y\) (такие \(x\)
располагаются вдоль сторон), то эта точка не включатся в число
информативных по стратегии c) (так как модель считает, что этот объект
не относится к тому классу).

\paragraph{Стратегия 2: отбор комитетом (query by
committee)}\label{ux441ux442ux440ux430ux442ux435ux433ux438ux44f-2-ux43eux442ux431ux43eux440-ux43aux43eux43cux438ux442ux435ux442ux43eux43c-query-by-committee}

\emph{Комитетом моделей} будем называть набор моделей, обученных на
одном и том же множестве \(L\). Обозначение ---
\(C_L = \{\theta_1,\ldots,\theta_m\}\). Идея стратегии: выбирать объекты
с наибольшей \emph{несогласованностью} комитетов моделей.

Пусть

\begin{itemize}
\item
  \(V(y, x) = |{\theta \in C_{L}: y_{\theta}(x) = y}|\) --- количество
  моделей из комитета \(C_{L}\), выбравших \(y\);
\item
  \(\hat{P}(y|x) = V(y, x) / |C_{L}|\) --- соответственно доля моделей,
  выбравших \(y\).
\end{itemize}

Тогда несогласованность можно определить через
\(\varphi_{\theta}(x) = - \sum_{y \in Y} \hat{P}(y|x) \log \hat{P}(y|x)\)
--- энтропию голосующей вероятности.

Как уже говорилось, максимум энтропии достигается на равномерном
распределении, значит, максимизация этого функционала соответсвует
выбору объекта, для которого \(V(y, x)\) примерно равны для каждого
\(y\).

\paragraph{Стратегия 3: Сокращение пространства решений (version space
reduction)}\label{ux441ux442ux440ux430ux442ux435ux433ux438ux44f-3-ux441ux43eux43aux440ux430ux449ux435ux43dux438ux435-ux43fux440ux43eux441ux442ux440ux430ux43dux441ux442ux432ux430-ux440ux435ux448ux435ux43dux438ux439-version-space-reduction}

Идея этого подхода заключается в уменьшении пространствами решений
(version space). Под пространством решений в общем случае понимают
множество гипотез, которые согласуются с текущими тренировочными
данными. Понятие получается довольно размытое, но в задаче классификации
гипотезы \emph{связаны} с всевозможными разделяющими гиперплоскостями и
т.п.

\begin{figure}[htbp]
\centering
\includegraphics[width=6.87500in]{img/vs.png}
\caption{Рис. 6: Примеры пространств решений}
\end{figure}

Поскольку пространство решений это очень широкое понятие, то стратегии
его уменьшения можно описать только на примере конкретной задачи. Ниже
приведен пример, как комбинируется SVM и активное обучение, и уменьшение
пространства решений его ключевая идея.

Стоит отметить, что отбор комитетом на самом деле тоже уменьшает
пространство решений.

\paragraph{Стратегия 4: ожидаемое влияние на модель (expected model
change)}\label{ux441ux442ux440ux430ux442ux435ux433ux438ux44f-4-ux43eux436ux438ux434ux430ux435ux43cux43eux435-ux432ux43bux438ux44fux43dux438ux435-ux43dux430-ux43cux43eux434ux435ux43bux44c-expected-model-change}

Идея: будем искать такой объект, добавление которого в обучающее
множество приведет к наибольшему \emph{изменению} параметра модели
\(\theta\). Само изменение будем мерять с помощью нормы градиента
функционала обучения \(\ell_{\theta}(L)\), где \(L\) --- обучающее
множество.

Нам нужно посчитать влияние на модель, но мы не знаем метку на \(x\) из
неразмеченного множества \(U\). Однако у нас есть апостриорное
распределение \(P_{\theta}(y|x)\), поэтому будем считать взвешенную
сумму
\(\varphi_{\theta}(x) = \sum_{y \in Y} P_{\theta}(y|x) \cdot \| \nabla\ell_{\theta}(L \cup \{(x, y)\})\|\),
другими словами, мат. ожидание нормы градиента.

Вспомните, что \(\nabla\ell_{\theta}(L) = 0\) (\(\theta\) оптимум на
обучающем множестве \(L\)), поэтому можно воспользоваться следующим
приближением
\(\nabla\ell_{\theta}(L \cup \{(x, y)\}) \approx \nabla\ell_{\theta}(\{(x, y)\})\)
для оптимизации вычислений.

\paragraph{Стратегия 5: ожидаемое уменьшение ошибки (expected error
reduction)}\label{ux441ux442ux440ux430ux442ux435ux433ux438ux44f-5-ux43eux436ux438ux434ux430ux435ux43cux43eux435-ux443ux43cux435ux43dux44cux448ux435ux43dux438ux435-ux43eux448ux438ux431ux43aux438-expected-error-reduction}

Идея: максимизация уверенности на остальных объектах в неразмеченном
множестве.

Пусть \(\theta_+(x, y)\) --- оптимальный вектор параметров после
дообучения модели на \(L \cup \{(x, y)\}\), а \(y^* = y^*(z)\) ---
наиболее вероятный класс для \(z\) в модели, обученной на \(L\).

Рассмотрим функционал
\(\varphi_{\theta}(x) = - \sum_{y \in Y} P_{\theta}(y|x) \sum_{z \in U} (1 - P_{\theta_+(x, y)}(y^*|z))\),
его максимизация соответствует минимизации
\(\sum_{y \in Y} P_{\theta}(y|x) \sum_{z \in U} (1 - P_{\theta_+(x, y)}(y^*|z))\).
То есть находим \(x\), добавление которого увеличивает
\(P_{\theta_+(x, y)}(y^*|z))\) (делает как можно ближе к \(1\)) для всех
неразмеченных \(z\). Так как метку для \(x\) мы не знаем, то делаем
усреднение по всем \(y\).

\emph{\textbf{Замечание}}: В стратегиях выбор по степени неуверенности,
отбор комитетом, ожидаемое влияние на модель к числу информативных
объектов могут попасть аутлаеры. Поэтому их нужно исключить заранее, или
рассмотривать не \(\max_{x \in U} \varphi_{\theta}(x)\), а
\(\max_{x \in U} \varphi_{\theta}(x)\cdot \big(\frac{1}{|U|}\sum_{z \in U}\rho(x, z)\big)^{\beta}\),
где \(\rho\) --- это некоторая мера близости объектов, \(\beta\) ---
нормировочный коэффициент, чтобы контролировать величину весов.
Последняя стратегия устойчива к выбросам.

\subsection{Активное обучение в
SVM}\label{ux430ux43aux442ux438ux432ux43dux43eux435-ux43eux431ux443ux447ux435ux43dux438ux435-ux432-svm}

Посмотрим, как активное обучение комбинируется с классическими методами
классификации, таким как SVM. Описанный ниже метод относится к статье
(Tong and Koller 2001), краткий обзор других статей на эту тему можно
найти в (Settles 2010).

Будем предполать, что:

\begin{itemize}
\item
  данные линейно разделимы (но подход можно адаптировать под допущение
  ограниченного кол-ва ошибок, применять kernel trick, как это сделано в
  SVM);
\item
  класса два, их метки \(1\) и \(-1\).
\end{itemize}

\paragraph{Напоминание}\label{ux43dux430ux43fux43eux43cux438ux43dux430ux43dux438ux435}

В обычном SVM ищется классификатор вида
\(f(x) = {\rm sign}(\langle x, w \rangle - w_0)\) и решается
оптимизационная задача \(\|w\|^2/2 \to \min_{w, w_0}\) при условиях
\(y_i(\langle x_i, w \rangle - w_0) \geq 1\), где \(w, w_0\) ---
параметры алгоритма.

Величина \(|\langle x_i, w \rangle - w_0|/\|w\|\) --- это расстояние от
точки \(x_i\) до разделяющей гиперплоскости
\(\langle x, w \rangle - w_0 = 0\), поэтому когда минимизируется
\(\|w\|\), максимизируется зазор между \emph{опорными} гиперплоскостями,
которые проходят через ближайшие к разделяющей гиперплоскости \(x_i\).
Можно считать, что \(\|w\| = 1\), тогда оптимизационную задачу можно
переписать как
\(\min_i y_i (\langle x_i, w \rangle - w_0) \to \max_{w, w_0}\) при
условиях \(\|w\| = 1\) и \(y_i(\langle x_i, w \rangle - w_0) \geq 1\).

\paragraph{О пространстве
решений}\label{ux43e-ux43fux440ux43eux441ux442ux440ux430ux43dux441ux442ux432ux435-ux440ux435ux448ux435ux43dux438ux439}

По определению пространством решений будет являться
\(\mathcal{V} = \{f |\, y_if(x_i) > 0,\, i = 1 \ldots n\}\). Поскольку
между \(f\) и \(w\) существует биекция, то можно считать, что
\(\mathcal{V} = \{w\,|\, \|w\| = 1,\, y_i (\langle x_i, w \rangle - w_0) > 0,\, i = 1\ldots n \}\).

Обозначим за \(Area(\mathcal{V})\) площадь пространства решений.

\paragraph{Теоретическое отступление, результат которого используется
дальше}\label{ux442ux435ux43eux440ux435ux442ux438ux447ux435ux441ux43aux43eux435-ux43eux442ux441ux442ux443ux43fux43bux435ux43dux438ux435-ux440ux435ux437ux443ux43bux44cux442ux430ux442-ux43aux43eux442ux43eux440ux43eux433ux43e-ux438ux441ux43fux43eux43bux44cux437ux443ux435ux442ux441ux44f-ux434ux430ux43bux44cux448ux435}

Если предположить, что \(\|x_i\| = 1\), то
\(\min_i y_i(\langle x_i, w \rangle - w_0) = \min_i |\langle w, y_i x_i\rangle - y_i w_0| = \min_i |\langle w, y_i x_i\rangle - y_i w_0|/\|y_ix_i\|\),
а значит зазор между гиперплоскостями также равен минимальному
расстоянию от \(w\) до гиперплоскости
\(\langle v, y_i x_i\rangle - y_i w_0 = 0\) относительно \(v\).

Отсюда следует, что оптимальный параметр \(w\) --- это центр гиперсферы
наибольшего радиуса в \(\mathcal{V}\), которая бы не пересекалась ни с
одной из гиперплоскостей полном пространстве.

\begin{figure}[htbp]
\centering
\includegraphics[width=5.72917in]{img/svm+al.png}
\caption{Рис. 7: Активное обучение в SVM}
\end{figure}

\paragraph{Об активном
обучении}\label{ux43eux431-ux430ux43aux442ux438ux432ux43dux43eux43c-ux43eux431ux443ux447ux435ux43dux438ux438}

Пусть также
\(\mathcal{V}_k^- = \mathcal{V}_k \cap \{w\,|\, \langle w, x\rangle < 0\}\)
и
\(\mathcal{V}_k^+ = \mathcal{V}_k \cap \{w\,|\, \langle w, x\rangle > 0\}\),
где \(\mathcal{V}_k\) --- это пространство решений после \(k\) итераций
активного обучения. Другими словами, \(\mathcal{V}_k^-\) и
\(\mathcal{V}_k^+\) --- это пространства решений, если метка для \(x\)
оказалась \(-1\) и \(1\) соответсвенно. Также за \(\mathcal{V}_k(\ell)\)
обозначим пространство решений после \(k\) итераций активного обучения,
который использует стратегию \(\ell\).

В (Tong and Koller 2001) приводится лемма, говорящая о том, что
оптимальной стратегий будет деление \(Area(\mathcal{V})\) примерно
пополам. Точнее, если выбрать такую стратегию в активном обучении,
которую условно обозначим за \(\ell^*\), то для любой другой стратегии
\(\ell\) выполняется неравенство:
\[\sup_{P \in \mathcal{P}} {\rm E}_P[Area(\mathcal{V}_i(\ell^*))] \leq \sup_{P \in \mathcal{P}} {\rm E}_P[Area(\mathcal{V}_i(\ell^*))]\]
для любого \(i \geq 1\), где \(\mathcal{P}\) --- множество всех условных
распределений \(P(y|x)\). При этом строгое неравенство достигается, если
существует итерация \(j \in 1,\ldots, i\), такая, что \(\ell\) не делит
пространство решений \(\mathcal{V}_{j - 1}\) пополам.

Пусть \(w_k\) --- центр гиперсферы наибольшего радиуса, которая вписана
в пространство решений \(\mathcal{V}_k\). Предлагается три способа
делить пространство решений так, чтобы площади полученных областей были
примерно равны:

\begin{itemize}
\tightlist
\item
  \emph{Simple Margin}. Теперь перебирая все неразмеченные объекты
  \(x\), выберем тот, для которого соответсвующая гиперплоскость ближе
  всего к центру \(w_k\). По отступлению выше такой \(x_k\) находится
  ближе всего к разделяющей гиперплоскости в пространстве объектов.
\end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics[width=5.72917in]{img/simplemargin.png}
\caption{Рис. 8: Simple Margin. (a) выбирается ближайшая гиперплоскость
b. (b) выбирается ближайшая гиперплоскость a}
\end{figure}

Обозначим за \(m_k\) радиус гиперсферы. Рассмотрим неразмеченный объект
\(x\), \(\mathcal{V}_k^-\), \(\mathcal{V}_k^+\) --- подпространства в
пространсве решений, соответствующие отрицательной и положительной метке
\(x\). Теперь обозначим за \(m^-_k\) и \(m^+_k\) радиусы вписанных в
\(\mathcal{V}_k^-\) и \(\mathcal{V}_k^+\) сфер.

\begin{itemize}
\item
  \emph{MaxMin Margin}. Эта стратегия предлагает искать
  \(\arg\max_x \min\{m^+_k, m^-_k\}\). Так как \(m_k\) cвязан с
  \(Area(\mathcal{V}_k)\), то на самом деле максимизируется
  \(\min\{Area(\mathcal{V}_k^+), Area(\mathcal{V}^-_k)\}\), тогда
  \(Area(\mathcal{V}_k^+)\) и \(Area(\mathcal{V}^-_k)\) будут
  максимально близки.
\item
  \emph{Ratio Margin}. В этой стратегии ищется
  \(\arg\max_x \min\{m^+/m^-, m^-/m^+\}\), она объясняется так же, как и
  стратегия MaxMin Margin.
\end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics[width=5.72917in]{img/maxminmargin.png}
\caption{Рис. 9: (a) MaxMin Margin --- выбирается гиперплоскость b. (b)
Ratio Margin --- выбирается гиперплоскость e}
\end{figure}

\subsection{Недостатки активного
обучения}\label{ux43dux435ux434ux43eux441ux442ux430ux442ux43aux438-ux430ux43aux442ux438ux432ux43dux43eux433ux43e-ux43eux431ux443ux447ux435ux43dux438ux44f}

Стратегии активного обучения устроены так, что они рекомендуют точки,
лежащие, например, вблизи разделяющей гиперплоскости в текущей модели.
Это хорошо работает, если нет крупных областей, где модель бы ошибалась.
Таким образом, у алгоритма среди данных есть необследованные участки,
что повышается ошибку на тестовых данных.

Возникает так называемая exploration-exploitation dilemma, но есть
приемы, связанные с применением контекстных бандитов (см. Bouneffouf and
others 2014) и случайным изучением всего неразмеченного множества (см.
Bouneffouf 2015), которые не увеличивают время обучения так, что сама
идея активного обучения теряет смысл.

\subsection*{Литература}\label{ux43bux438ux442ux435ux440ux430ux442ux443ux440ux430}
\addcontentsline{toc}{subsection}{Литература}

\hypertarget{refs}{}
\hypertarget{ref-Bouneffouf2}{}
Bouneffouf, Djallel. 2015. ``Exponentiated Gradient Exploration for
Active Learning.''

\hypertarget{ref-Bouneffouf1}{}
Bouneffouf, Djallel, and others. 2014. ``Contextual Bandit for Active
Learning: Active Thompson Sampling.''

\hypertarget{ref-DDBAL}{}
Jiang, Jun, and Horace Ip. 2007. ``Dynamic Distance-Based Active
Learning with SVM.'' \emph{Machine Learning and Data Mining in Pattern
Recognition. Lecture Notes in Artificial Intelligence}. Springer-Verlag
Berlin Heidelberg.

\hypertarget{ref-Settles}{}
Settles, Burr. 2010. ``Active Learning Literature Survey.'' Computer
Sciences Technical Report 1648. University of Wisconsin--Madison.

\hypertarget{ref-TongKoller}{}
Tong, Simon, and Daphne Koller. 2001. ``Support Vector Machine Active
Learning with Applications to Text Classification.'' \emph{Journal of
Machine Learning Research}, 45--66.

\end{document}
